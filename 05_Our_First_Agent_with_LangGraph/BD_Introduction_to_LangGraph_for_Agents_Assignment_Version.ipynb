{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "90ca81bde4b7409b8ad0408350d3dacc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba34c40da915427c97a35365a74ed548",
              "IPY_MODEL_12594fdddafe48c38e224beb97b24a7b",
              "IPY_MODEL_a4c0da2829704de79223aa84af932e0f"
            ],
            "layout": "IPY_MODEL_6fc846aafd16460eade00e3d087b1547"
          }
        },
        "ba34c40da915427c97a35365a74ed548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1a2fa24d58e4f0084d9db755bb59e01",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b34ee74919bd40919e51d171464824b0",
            "value": ""
          }
        },
        "12594fdddafe48c38e224beb97b24a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66134ba838604465bbac92a48edfc5a5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_032c5ecba2614c7da37859cee77dd470",
            "value": 1
          }
        },
        "a4c0da2829704de79223aa84af932e0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_492f964ab41d46c58933cec0cf627d8a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4fba9013a3364ce490fbec88334806c9",
            "value": "‚Äá4/?‚Äá[00:16&lt;00:00,‚Äá‚Äá4.46s/it]"
          }
        },
        "6fc846aafd16460eade00e3d087b1547": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1a2fa24d58e4f0084d9db755bb59e01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b34ee74919bd40919e51d171464824b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66134ba838604465bbac92a48edfc5a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "032c5ecba2614c7da37859cee77dd470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "492f964ab41d46c58933cec0cf627d8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fba9013a3364ce490fbec88334806c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LangGraph and LangSmith - Agentic RAG Powered by LangChain\n",
        "\n",
        "In the following notebook we'll complete the following tasks:\n",
        "\n",
        "- ü§ù Breakout Room #1:\n",
        "  1. Install required libraries\n",
        "  2. Set Environment Variables\n",
        "  3. Creating our Tool Belt\n",
        "  4. Creating Our State\n",
        "  5. Creating and Compiling A Graph!\n",
        "\n",
        "  - ü§ù Breakout Room #2:\n",
        "  1. Evaluating the LangGraph Application with LangSmith\n",
        "  2. Adding Helpfulness Check and \"Loop\" Limits\n",
        "  3. LangGraph for the \"Patterns\" of GenAI"
      ],
      "metadata": {
        "id": "gJXW_DgiSebM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ù Breakout Room #1"
      ],
      "metadata": {
        "id": "djQ3nRAgoF67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: LangGraph - Building Cyclic Applications with LangChain\n",
        "\n",
        "LangGraph is a tool that leverages LangChain Expression Language to build coordinated multi-actor and stateful applications that includes cyclic behaviour.\n",
        "\n",
        "### Why Cycles?\n",
        "\n",
        "In essence, we can think of a cycle in our graph as a more robust and customizable loop. It allows us to keep our application agent-forward while still giving the powerful functionality of traditional loops.\n",
        "\n",
        "Due to the inclusion of cycles over loops, we can also compose rather complex flows through our graph in a much more readable and natural fashion. Effectively allowing us to recreate application flowcharts in code in an almost 1-to-1 fashion.\n",
        "\n",
        "### Why LangGraph?\n",
        "\n",
        "Beyond the agent-forward approach - we can easily compose and combine traditional \"DAG\" (directed acyclic graph) chains with powerful cyclic behaviour due to the tight integration with LCEL. This means it's a natural extension to LangChain's core offerings!"
      ],
      "metadata": {
        "id": "e7pQDUhUnIo8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1:  Dependencies\n",
        "\n",
        "We'll first install all our required libraries.\n",
        "\n",
        "> NOTE: If you're running this locally - please skip this step."
      ],
      "metadata": {
        "id": "3_fLDElOVoop"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KaVwN269EttM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "100d5740-fd64-48bd-fb3c-58c2de49224b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m148.7/148.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m412.7/412.7 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain langchain_openai langchain-community langgraph arxiv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: Environment Variables\n",
        "\n",
        "We'll want to set both our OpenAI API key and our LangSmith environment variables."
      ],
      "metadata": {
        "id": "wujPjGJuoPwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdh8CoVWHRvs",
        "outputId": "826b031f-95fa-4341-9767-09ed8cb46df4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BLmneW40276B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jkla2fpx28QK",
        "outputId": "84ec4e0b-9c1c-41aa-e8fa-57248827a9bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TAVILY_API_KEY¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE5 - LangGraph - {uuid4().hex[0:8]}\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv0glIDyHmRt",
        "outputId": "95ba8e8d-c8d9-4107-e7d1-e6278b9e9212"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangSmith API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3: Creating our Tool Belt\n",
        "\n",
        "As is usually the case, we'll want to equip our agent with a toolbelt to help answer questions and add external knowledge.\n",
        "\n",
        "There's a tonne of tools in the [LangChain Community Repo](https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community/tools) but we'll stick to a couple just so we can observe the cyclic nature of LangGraph in action!\n",
        "\n",
        "We'll leverage:\n",
        "\n",
        "- [Tavily Search Results](https://github.com/langchain-ai/langchain/blob/master/libs/community/langchain_community/tools/tavily_search/tool.py)\n",
        "- [Arxiv](https://github.com/langchain-ai/langchain/tree/master/libs/community/langchain_community/tools/arxiv)"
      ],
      "metadata": {
        "id": "sBRyQmEAVzua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####üèóÔ∏è Activity #1:\n",
        "\n",
        "Please add the tools to use into our toolbelt.\n",
        "\n",
        "> NOTE: Each tool in our toolbelt should be a method."
      ],
      "metadata": {
        "id": "2k6n_Dob2F46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5)\n",
        "\n",
        "tool_belt = [\n",
        "    tavily_tool,\n",
        "    ArxivQueryRun(),\n",
        "]"
      ],
      "metadata": {
        "id": "lAxaSvlfIeOg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model\n",
        "\n",
        "Now we can set-up our model! We'll leverage the familiar OpenAI model suite for this example - but it's not *necessary* to use with LangGraph. LangGraph supports all models - though you might not find success with smaller models - as such, they recommend you stick with:\n",
        "\n",
        "- OpenAI's GPT-3.5 and GPT-4\n",
        "- Anthropic's Claude\n",
        "- Google's Gemini\n",
        "\n",
        "> NOTE: Because we're leveraging the OpenAI function calling API - we'll need to use OpenAI *for this specific example* (or any other service that exposes an OpenAI-style function calling API."
      ],
      "metadata": {
        "id": "VI-C669ZYVI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
      ],
      "metadata": {
        "id": "QkNS8rNZJs4z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our model set-up, let's \"put on the tool belt\", which is to say: We'll bind our LangChain formatted tools to the model in an OpenAI function calling format."
      ],
      "metadata": {
        "id": "Ugkj3GzuZpQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.bind_tools(tool_belt)"
      ],
      "metadata": {
        "id": "4OdMqFafZ_0V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ‚ùì Question #1:\n",
        "\n",
        "How does the model determine which tool to use?\n",
        "\n",
        "-- Uses the tool description and uses the last message to logically infer which tool to use, for this we often require a strong inference model"
      ],
      "metadata": {
        "id": "ERzuGo6W18Lr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4: Putting the State in Stateful\n",
        "\n",
        "Earlier we used this phrasing:\n",
        "\n",
        "`coordinated multi-actor and stateful applications`\n",
        "\n",
        "So what does that \"stateful\" mean?\n",
        "\n",
        "To put it simply - we want to have some kind of object which we can pass around our application that holds information about what the current situation (state) is. Since our system will be constructed of many parts moving in a coordinated fashion - we want to be able to ensure we have some commonly understood idea of that state.\n",
        "\n",
        "LangGraph leverages a `StatefulGraph` which uses an `AgentState` object to pass information between the various nodes of the graph.\n",
        "\n",
        "There are more options than what we'll see below - but this `AgentState` object is one that is stored in a `TypedDict` with the key `messages` and the value is a `Sequence` of `BaseMessages` that will be appended to whenever the state changes.\n",
        "\n",
        "Let's think about a simple example to help understand exactly what this means (we'll simplify a great deal to try and clearly communicate what state is doing):\n",
        "\n",
        "1. We initialize our state object:\n",
        "  - `{\"messages\" : []}`\n",
        "2. Our user submits a query to our application.\n",
        "  - New State: `HumanMessage(#1)`\n",
        "  - `{\"messages\" : [HumanMessage(#1)}`\n",
        "3. We pass our state object to an Agent node which is able to read the current state. It will use the last `HumanMessage` as input. It gets some kind of output which it will add to the state.\n",
        "  - New State: `AgentMessage(#1, additional_kwargs {\"function_call\" : \"WebSearchTool\"})`\n",
        "  - `{\"messages\" : [HumanMessage(#1), AgentMessage(#1, ...)]}`\n",
        "4. We pass our state object to a \"conditional node\" (more on this later) which reads the last state to determine if we need to use a tool - which it can determine properly because of our provided object!"
      ],
      "metadata": {
        "id": "_296Ub96Z_H8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "import operator\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[list, add_messages]"
      ],
      "metadata": {
        "id": "mxL9b_NZKUdL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 5: It's Graphing Time!\n",
        "\n",
        "Now that we have state, and we have tools, and we have an LLM - we can finally start making our graph!\n",
        "\n",
        "Let's take a second to refresh ourselves about what a graph is in this context.\n",
        "\n",
        "Graphs, also called networks in some circles, are a collection of connected objects.\n",
        "\n",
        "The objects in question are typically called nodes, or vertices, and the connections are called edges.\n",
        "\n",
        "Let's look at a simple graph.\n",
        "\n",
        "![image](https://i.imgur.com/2NFLnIc.png)\n",
        "\n",
        "Here, we're using the coloured circles to represent the nodes and the yellow lines to represent the edges. In this case, we're looking at a fully connected graph - where each node is connected by an edge to each other node.\n",
        "\n",
        "If we were to think about nodes in the context of LangGraph - we would think of a function, or an LCEL runnable.\n",
        "\n",
        "If we were to think about edges in the context of LangGraph - we might think of them as \"paths to take\" or \"where to pass our state object next\".\n",
        "\n",
        "Let's create some nodes and expand on our diagram.\n",
        "\n",
        "> NOTE: Due to the tight integration with LCEL - we can comfortably create our nodes in an async fashion!"
      ],
      "metadata": {
        "id": "vWsMhfO9grLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "def call_model(state):\n",
        "  messages = state[\"messages\"]\n",
        "  response = model.invoke(messages)\n",
        "  return {\"messages\" : [response]}\n",
        "\n",
        "tool_node = ToolNode(tool_belt)"
      ],
      "metadata": {
        "id": "91flJWtZLUrl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have two total nodes. We have:\n",
        "\n",
        "- `call_model` is a node that will...well...call the model\n",
        "- `tool_node` is a node which can call a tool\n",
        "\n",
        "Let's start adding nodes! We'll update our diagram along the way to keep track of what this looks like!\n"
      ],
      "metadata": {
        "id": "2bwR7MgWj3Wg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "uncompiled_graph = StateGraph(AgentState)\n",
        "\n",
        "uncompiled_graph.add_node(\"agent\", call_model)\n",
        "uncompiled_graph.add_node(\"action\", tool_node)"
      ],
      "metadata": {
        "id": "_vF4_lgtmQNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fca5a6a-bd91-4845-9377-05106ce400a0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7aeb1ce8dd90>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at what we have so far:\n",
        "\n",
        "![image](https://i.imgur.com/md7inqG.png)"
      ],
      "metadata": {
        "id": "b8CjRlbVmRpW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll add our entrypoint. All our entrypoint does is indicate which node is called first."
      ],
      "metadata": {
        "id": "uaXHpPeSnOWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uncompiled_graph.set_entry_point(\"agent\")"
      ],
      "metadata": {
        "id": "YGCbaYqRnmiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0328e105-73fb-44df-9420-1083e7a0084e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7aeb1ce8dd90>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image](https://i.imgur.com/wNixpJe.png)"
      ],
      "metadata": {
        "id": "BUsfGoSpoF9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we want to build a \"conditional edge\" which will use the output state of a node to determine which path to follow.\n",
        "\n",
        "We can help conceptualize this by thinking of our conditional edge as a conditional in a flowchart!\n",
        "\n",
        "Notice how our function simply checks if there is a \"function_call\" kwarg present.\n",
        "\n",
        "Then we create an edge where the origin node is our agent node and our destination node is *either* the action node or the END (finish the graph).\n",
        "\n",
        "It's important to highlight that the dictionary passed in as the third parameter (the mapping) should be created with the possible outputs of our conditional function in mind. In this case `should_continue` outputs either `\"end\"` or `\"continue\"` which are subsequently mapped to the action node or the END node."
      ],
      "metadata": {
        "id": "0Q_pQgHmoW0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def should_continue(state):\n",
        "  last_message = state[\"messages\"][-1]\n",
        "\n",
        "  if last_message.tool_calls:\n",
        "    return \"action\"\n",
        "\n",
        "  return END\n",
        "\n",
        "uncompiled_graph.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    should_continue\n",
        ")"
      ],
      "metadata": {
        "id": "1BZgb81VQf9o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9561f42f-6eeb-44af-c56d-f4379c001e1b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7aeb1ce8dd90>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize what this looks like.\n",
        "\n",
        "![image](https://i.imgur.com/8ZNwKI5.png)"
      ],
      "metadata": {
        "id": "-Cvhcf4jp0Ce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can add our last edge which will connect our action node to our agent node. This is because we *always* want our action node (which is used to call our tools) to return its output to our agent!"
      ],
      "metadata": {
        "id": "yKCjWJCkrJb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uncompiled_graph.add_edge(\"action\", \"agent\")"
      ],
      "metadata": {
        "id": "UvcgbHf1rIXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1edfb84-a76a-4eea-d806-fccd07142b33"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7aeb1ce8dd90>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the final visualization.\n",
        "\n",
        "![image](https://i.imgur.com/NWO7usO.png)"
      ],
      "metadata": {
        "id": "EiWDwBQtrw7Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All that's left to do now is to compile our workflow - and we're off!"
      ],
      "metadata": {
        "id": "KYqDpErlsCsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compiled_graph = uncompiled_graph.compile()"
      ],
      "metadata": {
        "id": "zt9-KS8DpzNx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ‚ùì Question #2:\n",
        "\n",
        "Is there any specific limit to how many times we can cycle?\n",
        "\n",
        "If not, how could we impose a limit to the number of cycles?\n",
        "\n",
        "Default is 25, we can change this behavior by setting the max cycle param via GraphExecutor function under langgraph.graph.runner\n"
      ],
      "metadata": {
        "id": "xhNWIwBL1W4Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Our Graph\n",
        "\n",
        "Now that we've created and compiled our graph - we can call it *just as we'd call any other* `Runnable`!\n",
        "\n",
        "Let's try out a few examples to see how it fairs:"
      ],
      "metadata": {
        "id": "VEYcTShCsPaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "inputs = {\"messages\" : [HumanMessage(content=\"Who is the current captain of the Winnipeg Jets?\")]}\n",
        "\n",
        "async for chunk in compiled_graph.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        print(values[\"messages\"])\n",
        "        print(\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn4n37PQRPII",
        "outputId": "4ae0e487-f70f-4bc1-8a66-86945199794f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YpazfSVJ6QYTIXOMl0S89YgP', 'function': {'arguments': '{\"query\":\"current captain of the Winnipeg Jets 2023\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 162, 'total_tokens': 189, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-af2a6981-2478-41f2-a44b-7fb711e12f26-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current captain of the Winnipeg Jets 2023'}, 'id': 'call_YpazfSVJ6QYTIXOMl0S89YgP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 162, 'output_tokens': 27, 'total_tokens': 189, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "[ToolMessage(content='[{\"url\": \"https://thehockeynews.com/nhl/winnipeg-jets/news/jets-name-adam-lowry-as-team-captain\", \"content\": \"Jets Name Adam Lowry as Team Captain - The Hockey News Winnipeg Jets News, Analysis and More My Account Subscriptions Jets Name Adam Lowry as Team Captain The Winnipeg Jets will have a captain for the 2023-24 season. After going captain-less in 2022-23, the Winnipeg Jets unveiled Adam Lowry as the club\\'s new captain on Tuesday morning. Having stripped Wheeler of the \\'C\\' upon joining the Jets last season, head coach Rick Bowness rolled with three alternates in 2022-23, as Lowry, Josh Morrissey and Mark Scheifele each served in leadership roles with the club. Although it will be his first time serving as a team captain since his final year with the Swift Current Broncos in 2012-13, Lowry won\\'t need to look far for leadership examples.\"}, {\"url\": \"https://www.nytimes.com/athletic/4855976/2023/09/12/adam-lowry-jets-captain/\", \"content\": \"Jets name Adam Lowry as captain ahead of 2023-24 season: Why Winnipeg chose him - The Athletic Jets name Adam Lowry as captain ahead of 2023-24 season: Why Winnipeg chose him The team gave forward Adam Lowry the honor Tuesday, making him the third captain in franchise history since the Jets moved from Atlanta. Lowry did exactly that, stitched an ‚ÄúA‚Äù on his sweater for the first time in 2022-23, and is now captain of the Winnipeg Jets. Morrissey would have been a worthy choice as captain and is more of an impact player at his position than Lowry is. Lowry served as an assistant captain for the first time last season with Morrissey and Scheifele.\"}, {\"url\": \"https://thehockeynews.com/news/winnipeg-jets-name-adam-lowry-captain\", \"content\": \"Winnipeg Jets Name Adam Lowry Captain - The Hockey News Winnipeg Jets Name Adam Lowry Captain The Winnipeg Jets have named Adam Lowry the third captain in franchise history. Lowry becomes the third captain in Jets franchise history and takes over the role after Blake Wheeler served in it for six years before being stripped of the captaincy prior to the 2022-23 season. The 30-year-old Lowry has spent his entire nine-year NHL career with the Jets, logging 621 regular-season games with the franchise and racking up 93 goals and 111 assists for 204 points in the process. That is the question facing the Canadiens, Red Wings, Bruins, Canucks and six other squads as NHL trade deadline season kicks into gear.\"}, {\"url\": \"https://www.tsn.ca/nhl/winnipeg-jets-name-adam-lowry-captain-1.2006649\", \"content\": \"Winnipeg Jets name Adam Lowry captain | TSN TSN+ TSN+ TSN+ What is TSN+ Jets name Lowry captain ahead of his 10th season with team ![Image 70: Adam Lowry Winnipeg Jets](https://www.tsn.ca/content/dam/tsn/en/home/images/2023/4/22/adam-lowry-1-1950014-1682371533274.jpeg)Adam Lowry - Getty Images WINNIPEG ‚Äî The pride in Adam Lowry\\'s voice was evident after being named captain of the Winnipeg Jets on Tuesday. ‚ÄúNow the organization is being led by someone that was a true Winnipeg Jet from day one,‚Äù said Jets general manager Kevin Cheveldayoff, who drafted the forward in 2011. \\\\\"We believe the time is right for Adam Lowry to assume this role and set the standard for the way the Winnipeg Jets will move forward with new leadership and new purpose.‚Äù\"}, {\"url\": \"https://globalnews.ca/news/9954570/winnipeg-jets-adam-lowry-captain/\", \"content\": \"Lowry, 30, becomes the third captain in Jets 2.0 history, following in the footsteps of Andrew Ladd, who announced his retirement from hockey on Sunday, and Blake Wheeler.\"}]', name='tavily_search_results_json', id='68fb9fbd-7945-4ca1-9706-b3b9d7d27b32', tool_call_id='call_YpazfSVJ6QYTIXOMl0S89YgP', artifact={'query': 'current captain of the Winnipeg Jets 2023', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Jets Name Adam Lowry as Team Captain - The Hockey News', 'url': 'https://thehockeynews.com/nhl/winnipeg-jets/news/jets-name-adam-lowry-as-team-captain', 'content': \"Jets Name Adam Lowry as Team Captain - The Hockey News Winnipeg Jets News, Analysis and More My Account Subscriptions Jets Name Adam Lowry as Team Captain The Winnipeg Jets will have a captain for the 2023-24 season. After going captain-less in 2022-23, the Winnipeg Jets unveiled Adam Lowry as the club's new captain on Tuesday morning. Having stripped Wheeler of the 'C' upon joining the Jets last season, head coach Rick Bowness rolled with three alternates in 2022-23, as Lowry, Josh Morrissey and Mark Scheifele each served in leadership roles with the club. Although it will be his first time serving as a team captain since his final year with the Swift Current Broncos in 2012-13, Lowry won't need to look far for leadership examples.\", 'score': 0.9227683, 'raw_content': None}, {'title': 'Jets name Adam Lowry as captain ahead of 2023-24 season: Why Winnipeg ...', 'url': 'https://www.nytimes.com/athletic/4855976/2023/09/12/adam-lowry-jets-captain/', 'content': 'Jets name Adam Lowry as captain ahead of 2023-24 season: Why Winnipeg chose him - The Athletic Jets name Adam Lowry as captain ahead of 2023-24 season: Why Winnipeg chose him The team gave forward Adam Lowry the honor Tuesday, making him the third captain in franchise history since the Jets moved from Atlanta. Lowry did exactly that, stitched an ‚ÄúA‚Äù on his sweater for the first time in 2022-23, and is now captain of the Winnipeg Jets. Morrissey would have been a worthy choice as captain and is more of an impact player at his position than Lowry is. Lowry served as an assistant captain for the first time last season with Morrissey and Scheifele.', 'score': 0.8991304, 'raw_content': None}, {'title': 'Winnipeg Jets Name Adam Lowry Captain - The Hockey News', 'url': 'https://thehockeynews.com/news/winnipeg-jets-name-adam-lowry-captain', 'content': 'Winnipeg Jets Name Adam Lowry Captain - The Hockey News Winnipeg Jets Name Adam Lowry Captain The Winnipeg Jets have named Adam Lowry the third captain in franchise history. Lowry becomes the third captain in Jets franchise history and takes over the role after Blake Wheeler served in it for six years before being stripped of the captaincy prior to the 2022-23 season. The 30-year-old Lowry has spent his entire nine-year NHL career with the Jets, logging 621 regular-season games with the franchise and racking up 93 goals and 111 assists for 204 points in the process. That is the question facing the Canadiens, Red Wings, Bruins, Canucks and six other squads as NHL trade deadline season kicks into gear.', 'score': 0.8708723, 'raw_content': None}, {'title': 'Winnipeg Jets name Adam Lowry captain | TSN', 'url': 'https://www.tsn.ca/nhl/winnipeg-jets-name-adam-lowry-captain-1.2006649', 'content': 'Winnipeg Jets name Adam Lowry captain | TSN TSN+ TSN+ TSN+ What is TSN+ Jets name Lowry captain ahead of his 10th season with team ![Image 70: Adam Lowry Winnipeg Jets](https://www.tsn.ca/content/dam/tsn/en/home/images/2023/4/22/adam-lowry-1-1950014-1682371533274.jpeg)Adam Lowry - Getty Images WINNIPEG ‚Äî The pride in Adam Lowry\\'s voice was evident after being named captain of the Winnipeg Jets on Tuesday. ‚ÄúNow the organization is being led by someone that was a true Winnipeg Jet from day one,‚Äù said Jets general manager Kevin Cheveldayoff, who drafted the forward in 2011. \"We believe the time is right for Adam Lowry to assume this role and set the standard for the way the Winnipeg Jets will move forward with new leadership and new purpose.‚Äù', 'score': 0.8682137, 'raw_content': None}, {'title': 'Winnipeg Jets announce Adam Lowry as new captain - Global News', 'url': 'https://globalnews.ca/news/9954570/winnipeg-jets-adam-lowry-captain/', 'content': 'Lowry, 30, becomes the third captain in Jets 2.0 history, following in the footsteps of Andrew Ladd, who announced his retirement from hockey on Sunday, and Blake Wheeler.', 'score': 0.740494, 'raw_content': None}], 'response_time': 1.76})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='The current captain of the Winnipeg Jets is Adam Lowry.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 1085, 'total_tokens': 1099, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'stop', 'logprobs': None}, id='run-0ad94406-a143-4023-9237-98cc7b718450-0', usage_metadata={'input_tokens': 1085, 'output_tokens': 14, 'total_tokens': 1099, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at what happened:\n",
        "\n",
        "1. Our state object was populated with our request\n",
        "2. The state object was passed into our entry point (agent node) and the agent node added an `AIMessage` to the state object and passed it along the conditional edge\n",
        "3. The conditional edge received the state object, found the \"tool_calls\" `additional_kwarg`, and sent the state object to the action node\n",
        "4. The action node added the response from the OpenAI function calling endpoint to the state object and passed it along the edge to the agent node\n",
        "5. The agent node added a response to the state object and passed it along the conditional edge\n",
        "6. The conditional edge received the state object, could not find the \"tool_calls\" `additional_kwarg` and passed the state object to END where we see it output in the cell above!\n",
        "\n",
        "Now let's look at an example that shows a multiple tool usage - all with the same flow!"
      ],
      "metadata": {
        "id": "DBHnUtLSscRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"messages\" : [HumanMessage(content=\"Search Arxiv for the Knowledge Distillation paper, then search each of the authors to find out their latest Tweet using Tavily!\")]}\n",
        "\n",
        "async for chunk in compiled_graph.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        if node == \"action\":\n",
        "          print(f\"Tool Used: {values['messages'][0].name}\")\n",
        "        print(values[\"messages\"])\n",
        "\n",
        "        print(\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afv2BuEsV5JG",
        "outputId": "2c1ae792-35b3-4a83-ec09-277cdd6d2492"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_bGURQqziaRVYruUenoHblgfQ', 'function': {'arguments': '{\"query\":\"Knowledge Distillation\"}', 'name': 'arxiv'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 178, 'total_tokens': 195, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-5061fd00-146f-4fc8-b82c-3f7c57aa6ef8-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'Knowledge Distillation'}, 'id': 'call_bGURQqziaRVYruUenoHblgfQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 178, 'output_tokens': 17, 'total_tokens': 195, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "Tool Used: arxiv\n",
            "[ToolMessage(content='Published: 2023-04-10\\nTitle: A Survey on Recent Teacher-student Learning Studies\\nAuthors: Minghong Gao\\nSummary: Knowledge distillation is a method of transferring the knowledge from a\\ncomplex deep neural network (DNN) to a smaller and faster DNN, while preserving\\nits accuracy. Recent variants of knowledge distillation include teaching\\nassistant distillation, curriculum distillation, mask distillation, and\\ndecoupling distillation, which aim to improve the performance of knowledge\\ndistillation by introducing additional components or by changing the learning\\nprocess. Teaching assistant distillation involves an intermediate model called\\nthe teaching assistant, while curriculum distillation follows a curriculum\\nsimilar to human education. Mask distillation focuses on transferring the\\nattention mechanism learned by the teacher, and decoupling distillation\\ndecouples the distillation loss from the task loss. Overall, these variants of\\nknowledge distillation have shown promising results in improving the\\nperformance of knowledge distillation.\\n\\nPublished: 2022-05-05\\nTitle: Spot-adaptive Knowledge Distillation\\nAuthors: Jie Song, Ying Chen, Jingwen Ye, Mingli Song\\nSummary: Knowledge distillation (KD) has become a well established paradigm for\\ncompressing deep neural networks. The typical way of conducting knowledge\\ndistillation is to train the student network under the supervision of the\\nteacher network to harness the knowledge at one or multiple spots (i.e.,\\nlayers) in the teacher network. The distillation spots, once specified, will\\nnot change for all the training samples, throughout the whole distillation\\nprocess. In this work, we argue that distillation spots should be adaptive to\\ntraining samples and distillation epochs. We thus propose a new distillation\\nstrategy, termed spot-adaptive KD (SAKD), to adaptively determine the\\ndistillation spots in the teacher network per sample, at every training\\niteration during the whole distillation period. As SAKD actually focuses on\\n\"where to distill\" instead of \"what to distill\" that is widely investigated by\\nmost existing works, it can be seamlessly integrated into existing distillation\\nmethods to further improve their performance. Extensive experiments with 10\\nstate-of-the-art distillers are conducted to demonstrate the effectiveness of\\nSAKD for improving their distillation performance, under both homogeneous and\\nheterogeneous distillation settings. Code is available at\\nhttps://github.com/zju-vipa/spot-adaptive-pytorch\\n\\nPublished: 2020-11-30\\nTitle: A Selective Survey on Versatile Knowledge Distillation Paradigm for Neural Network Models\\nAuthors: Jeong-Hoe Ku, JiHun Oh, YoungYoon Lee, Gaurav Pooniwala, SangJeong Lee\\nSummary: This paper aims to provide a selective survey about knowledge\\ndistillation(KD) framework for researchers and practitioners to take advantage\\nof it for developing new optimized models in the deep neural network field. To\\nthis end, we give a brief overview of knowledge distillation and some related\\nworks including learning using privileged information(LUPI) and generalized\\ndistillation(GD). Even though knowledge distillation based on the\\nteacher-student architecture was initially devised as a model compression\\ntechnique, it has found versatile applications over various frameworks.\\n  In this paper, we review the characteristics of knowledge distillation from\\nthe hypothesis that the three important ingredients of knowledge distillation\\nare distilled knowledge and loss,teacher-student paradigm, and the distillation\\nprocess. In addition, we survey the versatility of the knowledge distillation\\nby studying its direct applications and its usage in combination with other\\ndeep learning paradigms. Finally we present some future works in knowledge\\ndistillation including explainable knowledge distillation where the analytical\\nanalysis of the performance gain is studied and the self-supervised learning\\nwhich is a hot research topic in deep learning community.', name='arxiv', id='a83262ab-42dd-492d-ab2b-4582b50f0a16', tool_call_id='call_bGURQqziaRVYruUenoHblgfQ')]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_8HaGRPgdUjF7YqTnnvOGCwUh', 'function': {'arguments': '{\"query\": \"Minghong Gao latest tweet\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_YHMNbMOmyL5eBdNJqmYXYTwB', 'function': {'arguments': '{\"query\": \"Jie Song latest tweet\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_dkjgdqTpK1hRYKYxU0FKgXdV', 'function': {'arguments': '{\"query\": \"Ying Chen latest tweet\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_YGrSK0iqHQv9zqH7rChLbtyx', 'function': {'arguments': '{\"query\": \"Jingwen Ye latest tweet\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_id4mtvEBZXHNggzhf5bjMECR', 'function': {'arguments': '{\"query\": \"Mingli Song latest tweet\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_fwJ4CtcvC7VVW7qNvrzvdcj3', 'function': {'arguments': '{\"query\": \"Jeong-Hoe Ku latest tweet\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_ilOJnsw1K836cRbs2RVFQIzy', 'function': {'arguments': '{\"query\": \"JiHun Oh latest tweet\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_Uu7PcfLMixxKayaPEv6QeMdE', 'function': {'arguments': '{\"query\": \"YoungYoon Lee latest tweet\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_1xVieiE7t3Pkw74jrQyaWsxr', 'function': {'arguments': '{\"query\": \"Gaurav Pooniwala latest tweet\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_QbYiJ0qetlchNIAPT346LP7t', 'function': {'arguments': '{\"query\": \"SangJeong Lee latest tweet\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 249, 'prompt_tokens': 998, 'total_tokens': 1247, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c481efa4-f034-4b7d-ba68-094196eb11bc-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Minghong Gao latest tweet'}, 'id': 'call_8HaGRPgdUjF7YqTnnvOGCwUh', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Jie Song latest tweet'}, 'id': 'call_YHMNbMOmyL5eBdNJqmYXYTwB', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Ying Chen latest tweet'}, 'id': 'call_dkjgdqTpK1hRYKYxU0FKgXdV', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Jingwen Ye latest tweet'}, 'id': 'call_YGrSK0iqHQv9zqH7rChLbtyx', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Mingli Song latest tweet'}, 'id': 'call_id4mtvEBZXHNggzhf5bjMECR', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Jeong-Hoe Ku latest tweet'}, 'id': 'call_fwJ4CtcvC7VVW7qNvrzvdcj3', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'JiHun Oh latest tweet'}, 'id': 'call_ilOJnsw1K836cRbs2RVFQIzy', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'YoungYoon Lee latest tweet'}, 'id': 'call_Uu7PcfLMixxKayaPEv6QeMdE', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Gaurav Pooniwala latest tweet'}, 'id': 'call_1xVieiE7t3Pkw74jrQyaWsxr', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'SangJeong Lee latest tweet'}, 'id': 'call_QbYiJ0qetlchNIAPT346LP7t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 998, 'output_tokens': 249, 'total_tokens': 1247, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "Tool Used: tavily_search_results_json\n",
            "[ToolMessage(content='[{\"url\": \"https://www.threads.net/@minghong.gao\", \"content\": \"49 Followers ‚Ä¢ 10 Threads. See the latest conversations with @minghong.gao.\"}, {\"url\": \"https://deepai.org/profile/minghong-gao\", \"content\": \"Read Minghong Gao\\'s latest research, browse their coauthor\\'s research, and play around with their algorithms\"}, {\"url\": \"https://www.imdb.com/name/nm4210946/news/\", \"content\": \"IMDb.com, Inc. takes no responsibility for the content or accuracy of the above news articles, Tweets, or blog posts. This content is published for the entertainment of our users only. The news articles, Tweets, and blog posts do not represent IMDb\\'s opinions nor can we guarantee that the reporting therein is completely factual. Please visit the source responsible for the item in question to\"}, {\"url\": \"https://muckrack.com/minghong-gao\", \"content\": \"Find Minghong Gao\\'s articles, email address, contact information, Twitter and more\"}, {\"url\": \"https://loop.frontiersin.org/people/1737967/overview\", \"content\": \"Loop is the open research network that increases the discoverability and impact of researchers and their work. Loop enables you to stay up-to-date with the latest discoveries and news, connect with researchers and form new collaborations.\"}]', name='tavily_search_results_json', id='67709a8d-be8c-4203-939c-473536b14628', tool_call_id='call_8HaGRPgdUjF7YqTnnvOGCwUh', artifact={'query': 'Minghong Gao latest tweet', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'È´òÈäòÈ¥ª (@minghong.gao) ‚Ä¢ Threads, Say more', 'url': 'https://www.threads.net/@minghong.gao', 'content': '49 Followers ‚Ä¢ 10 Threads. See the latest conversations with @minghong.gao.', 'score': 0.5040288, 'raw_content': None}, {'title': 'Minghong Gao - DeepAI', 'url': 'https://deepai.org/profile/minghong-gao', 'content': \"Read Minghong Gao's latest research, browse their coauthor's research, and play around with their algorithms\", 'score': 0.39901572, 'raw_content': None}, {'title': 'Minghong Gao - News - IMDb', 'url': 'https://www.imdb.com/name/nm4210946/news/', 'content': \"IMDb.com, Inc. takes no responsibility for the content or accuracy of the above news articles, Tweets, or blog posts. This content is published for the entertainment of our users only. The news articles, Tweets, and blog posts do not represent IMDb's opinions nor can we guarantee that the reporting therein is completely factual. Please visit the source responsible for the item in question to\", 'score': 0.3578373, 'raw_content': None}, {'title': \"Minghong Gao's Profile | MDPI Journalist | Muck Rack\", 'url': 'https://muckrack.com/minghong-gao', 'content': \"Find Minghong Gao's articles, email address, contact information, Twitter and more\", 'score': 0.34920028, 'raw_content': None}, {'title': 'Minghong Gao - Loop', 'url': 'https://loop.frontiersin.org/people/1737967/overview', 'content': 'Loop is the open research network that increases the discoverability and impact of researchers and their work. Loop enables you to stay up-to-date with the latest discoveries and news, connect with researchers and form new collaborations.', 'score': 0.25447235, 'raw_content': None}], 'response_time': 4.93}), ToolMessage(content='[{\"url\": \"https://twitter.com/JieSong95\", \"content\": \"The latest Tweets from Jie Song (@JieSong95). PhD in University of Geneva in Cognitive Neuroscience, Clinical Psychology and Spatial Navigation. Geneva, Switzerland\"}, {\"url\": \"https://twitter.com/Jiesongnyc\", \"content\": \"The latest Tweets from Jie Song (@Jiesongnyc). The one from the future. New York, NY\"}, {\"url\": \"https://twitter.com/smd1994\", \"content\": \"The latest Tweets from Jie Song (@smd1994)\"}, {\"url\": \"https://twitter.com/jie_song\", \"content\": \"The latest posts from @jie_song\"}, {\"url\": \"https://www.espn.com/mma/fighter/news/_/id/5138622/jie-song\", \"content\": \"Find the latest news about the MMA fighter Jie Song on ESPN. Check out news, rumors, and fight highlights.\"}]', name='tavily_search_results_json', id='318e25a7-861e-4386-a2b9-5995bc67ce56', tool_call_id='call_YHMNbMOmyL5eBdNJqmYXYTwB', artifact={'query': 'Jie Song latest tweet', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Jie Song (@JieSong95) | Twitter', 'url': 'https://twitter.com/JieSong95', 'content': 'The latest Tweets from Jie Song (@JieSong95). PhD in University of Geneva in Cognitive Neuroscience, Clinical Psychology and Spatial Navigation. Geneva, Switzerland', 'score': 0.8095324, 'raw_content': None}, {'title': 'Jie Song (@Jiesongnyc) | Twitter', 'url': 'https://twitter.com/Jiesongnyc', 'content': 'The latest Tweets from Jie Song (@Jiesongnyc). The one from the future. New York, NY', 'score': 0.8095324, 'raw_content': None}, {'title': 'Jie Song (@smd1994) | Twitter', 'url': 'https://twitter.com/smd1994', 'content': 'The latest Tweets from Jie Song (@smd1994)', 'score': 0.7756902, 'raw_content': None}, {'title': '@jie_song | X', 'url': 'https://twitter.com/jie_song', 'content': 'The latest posts from @jie_song', 'score': 0.560566, 'raw_content': None}, {'title': 'Jie Song MMA News - ESPN', 'url': 'https://www.espn.com/mma/fighter/news/_/id/5138622/jie-song', 'content': 'Find the latest news about the MMA fighter Jie Song on ESPN. Check out news, rumors, and fight highlights.', 'score': 0.34118778, 'raw_content': None}], 'response_time': 1.67}), ToolMessage(content='[{\"url\": \"https://twitter.com/YingChen160722\", \"content\": \"The latest Tweets from Ying Chen (@YingChen160722). Researcher, for researchers. IoPPN, King\\'s College London, UK\"}, {\"url\": \"https://twitter.com/yingchen874/status/1232373530991513607\", \"content\": \"\\\\\"@SlanderOfficial @SaidTheSky @jtroachmusic YES PLEASE HEAL ME\\\\\"\"}, {\"url\": \"https://twitter.com/YingChen_P\", \"content\": \"See new Tweets. Follow. Ying Chen @YingChen_P. Biochemistry and Structural Biology. Joined March 2017. 202 Following. 90 Followers. Tweets. Replies. Media. Likes. Ying Chen\\'s Tweets. Ying Chen Retweeted. Edoardo D\\'Imprima\"}, {\"url\": \"https://www.newschool.edu/nssr/faculty/Ying-Chen/\", \"content\": \"Profile **On leave Fall 2024-Spring 2025** Ying Chen is Associate Professor of Economics at the New School and holds a Ph.D. in Economics from University of Massachusetts Amherst. Her work explores the contradictions within capitalism and how they exhibit themselves.\"}, {\"url\": \"https://twitter.com/yingchen733\", \"content\": \"Ying Chen (@yingchen733) / Twitter ... Log in\"}]', name='tavily_search_results_json', id='0db50a03-f996-4e97-9d41-9878b193e475', tool_call_id='call_dkjgdqTpK1hRYKYxU0FKgXdV', artifact={'query': 'Ying Chen latest tweet', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Ying Chen (@YingChen160722) - Twitter', 'url': 'https://twitter.com/YingChen160722', 'content': \"The latest Tweets from Ying Chen (@YingChen160722). Researcher, for researchers. IoPPN, King's College London, UK\", 'score': 0.8415267, 'raw_content': None}, {'title': 'Ying Chen on Twitter: \"YES PLEASE HEAL ME‚Ä¶', 'url': 'https://twitter.com/yingchen874/status/1232373530991513607', 'content': '\"@SlanderOfficial @SaidTheSky @jtroachmusic YES PLEASE HEAL ME\"', 'score': 0.76617163, 'raw_content': None}, {'title': 'Ying Chen (@YingChen_P) / Twitter', 'url': 'https://twitter.com/YingChen_P', 'content': \"See new Tweets. Follow. Ying Chen @YingChen_P. Biochemistry and Structural Biology. Joined March 2017. 202 Following. 90 Followers. Tweets. Replies. Media. Likes. Ying Chen's Tweets. Ying Chen Retweeted. Edoardo D'Imprima\", 'score': 0.72019166, 'raw_content': None}, {'title': 'Ying Chen | The New School for Social Research', 'url': 'https://www.newschool.edu/nssr/faculty/Ying-Chen/', 'content': 'Profile **On leave Fall 2024-Spring 2025** Ying Chen is Associate Professor of Economics at the New School and holds a Ph.D. in Economics from University of Massachusetts Amherst. Her work explores the contradictions within capitalism and how they exhibit themselves.', 'score': 0.5852203, 'raw_content': None}, {'title': 'Ying Chen (@yingchen733) / Twitter', 'url': 'https://twitter.com/yingchen733', 'content': 'Ying Chen (@yingchen733) / Twitter ... Log in', 'score': 0.5501488, 'raw_content': None}], 'response_time': 1.87}), ToolMessage(content='[{\"url\": \"https://twitter.com/jingwenjw\", \"content\": \"The latest Tweets and replies from jingwen (@jingwenjw). 1999 ;\"}, {\"url\": \"https://jngwenye.github.io/\", \"content\": \"Jingwen Ye Welcome to my homepage! I\\'m Jingwen Ye, currently a research fellowship at Learning and Vision Lab, National University of SingaporeÔºå working with Prof. Xinchao Wang. I received my PhD from Zhejiang University, studying computer vision under Prof. Mingli Song and Chun Chen.\"}, {\"url\": \"https://sg.linkedin.com/in/jingweny0520/en\", \"content\": \"Research Fellow at National University of Singapore ¬∑ I\\'m Jingwen Ye, currently a research fellowship at Learning and Vision Lab, National University of Singapore, working with Prof. Xinchao Wang. I received my PhD from Zhejiang University, studying computer vision under Prof. Mingli Song and Chun Chen. Prior to that, I got my B. Eng. Degree from Dalian University of Technology. My\"}, {\"url\": \"https://deepai.org/profile/jingwen-ye\", \"content\": \"Read Jingwen Ye\\'s latest research, browse their coauthor\\'s research, and play around with their algorithms\"}, {\"url\": \"https://muckrack.com/jingwen-ye\", \"content\": \"Get in touch with Jingwen Contact Jingwen, search articles and Tweets, monitor coverage, and track replies from one place.\"}]', name='tavily_search_results_json', id='8c4b4914-9272-49df-9f92-c500ea3a81ed', tool_call_id='call_YGrSK0iqHQv9zqH7rChLbtyx', artifact={'query': 'Jingwen Ye latest tweet', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Tweets with replies by jingwen (@jingwenjw) | Twitter', 'url': 'https://twitter.com/jingwenjw', 'content': 'The latest Tweets and replies from jingwen (@jingwenjw). 1999 ;', 'score': 0.55796635, 'raw_content': None}, {'title': 'Jingwen Ye', 'url': 'https://jngwenye.github.io/', 'content': \"Jingwen Ye Welcome to my homepage! I'm Jingwen Ye, currently a research fellowship at Learning and Vision Lab, National University of SingaporeÔºå working with Prof. Xinchao Wang. I received my PhD from Zhejiang University, studying computer vision under Prof. Mingli Song and Chun Chen.\", 'score': 0.49011418, 'raw_content': None}, {'title': 'Jingwen YE - Research Fellow - Êñ∞Âä†Âù°ÂõΩÁ´ãÂ§ßÂ≠¶ | LinkedIn', 'url': 'https://sg.linkedin.com/in/jingweny0520/en', 'content': \"Research Fellow at National University of Singapore ¬∑ I'm Jingwen Ye, currently a research fellowship at Learning and Vision Lab, National University of Singapore, working with Prof. Xinchao Wang. I received my PhD from Zhejiang University, studying computer vision under Prof. Mingli Song and Chun Chen. Prior to that, I got my B. Eng. Degree from Dalian University of Technology. My\", 'score': 0.48718598, 'raw_content': None}, {'title': 'Jingwen Ye - DeepAI', 'url': 'https://deepai.org/profile/jingwen-ye', 'content': \"Read Jingwen Ye's latest research, browse their coauthor's research, and play around with their algorithms\", 'score': 0.41520765, 'raw_content': None}, {'title': \"Jingwen Ye's Profile | Muck Rack\", 'url': 'https://muckrack.com/jingwen-ye', 'content': 'Get in touch with Jingwen Contact Jingwen, search articles and Tweets, monitor coverage, and track replies from one place.', 'score': 0.3217162, 'raw_content': None}], 'response_time': 1.77}), ToolMessage(content='[{\"url\": \"https://twitter.com/mingli_song\", \"content\": \"The latest posts from @mingli_song\"}, {\"url\": \"https://twitter.com/MingLi_lab\", \"content\": \"See new Tweets. Follow. Click to Follow MingLi_lab. Ming Li @MingLi_lab. Principle Investigator in Institute of Microbiology, CAS. We work on CRISPR-Cas, TA and other anti-phage systems, and also develop new genetic tools. Beijing Joined March 2023. 39 Following. 13 Followers. Tweets. Replies. Media. Likes.\"}, {\"url\": \"https://twitter.com/MinggLi\", \"content\": \"See new Tweets. Follow. mingli @MinggLi. yo. Joined May 2011. 119 Following. 139 Followers. Tweets. ... Sign up to get Tweets about the Topics you follow in your Home timeline. Carousel. Viral Tweets. Popular videos. ... Music. mingli Retweeted.\"}, {\"url\": \"https://chaoweifang.github.io/authors/mingli-song/\", \"content\": \"Latest. Progressive Feature Self-Reinforcement for Weakly Supervised Semantic Segmentation\"}, {\"url\": \"https://scholar.google.com/citations?user=7oLbhAwAAAAJ&hl=en\", \"content\": \"New articles by this author. New citations to this author. ... Song, Mingli. Full Professor of Computer Science, Zhejiang University. Verified email at zju.edu.cn - Homepage. Computer Vision Deep Learning Pattern Recognition. ... D Tao, M Song, X Li, J Shen, J Sun, X Wu, C Faloutsos, SJ Maybank.\"}]', name='tavily_search_results_json', id='753aa0d3-38c6-4e58-9681-a2055192dbc9', tool_call_id='call_id4mtvEBZXHNggzhf5bjMECR', artifact={'query': 'Mingli Song latest tweet', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': '@mingli_song | X', 'url': 'https://twitter.com/mingli_song', 'content': 'The latest posts from @mingli_song', 'score': 0.55883324, 'raw_content': None}, {'title': 'Ming Li (@MingLi_lab) / Twitter', 'url': 'https://twitter.com/MingLi_lab', 'content': 'See new Tweets. Follow. Click to Follow MingLi_lab. Ming Li @MingLi_lab. Principle Investigator in Institute of Microbiology, CAS. We work on CRISPR-Cas, TA and other anti-phage systems, and also develop new genetic tools. Beijing Joined March 2023. 39 Following. 13 Followers. Tweets. Replies. Media. Likes.', 'score': 0.5411427, 'raw_content': None}, {'title': 'mingli (@MinggLi) / Twitter', 'url': 'https://twitter.com/MinggLi', 'content': 'See new Tweets. Follow. mingli @MinggLi. yo. Joined May 2011. 119 Following. 139 Followers. Tweets. ... Sign up to get Tweets about the Topics you follow in your Home timeline. Carousel. Viral Tweets. Popular videos. ... Music. mingli Retweeted.', 'score': 0.4836734, 'raw_content': None}, {'title': 'Mingli Song | Chaowei FANG', 'url': 'https://chaoweifang.github.io/authors/mingli-song/', 'content': 'Latest. Progressive Feature Self-Reinforcement for Weakly Supervised Semantic Segmentation', 'score': 0.42907107, 'raw_content': None}, {'title': '\\u202aSong, Mingli\\u202c - \\u202aGoogle Scholar\\u202c', 'url': 'https://scholar.google.com/citations?user=7oLbhAwAAAAJ&hl=en', 'content': 'New articles by this author. New citations to this author. ... Song, Mingli. Full Professor of Computer Science, Zhejiang University. Verified email at zju.edu.cn - Homepage. Computer Vision Deep Learning Pattern Recognition. ... D Tao, M Song, X Li, J Shen, J Sun, X Wu, C Faloutsos, SJ Maybank.', 'score': 0.41392776, 'raw_content': None}], 'response_time': 1.75}), ToolMessage(content='[{\"url\": \"https://twitter.com/kujeonghoon\", \"content\": \"The latest Tweets from Ku Jeong-hoon (@kujeonghoon). Gaming nerd, amateur artist, movie maniac, lone traveler, big fan of CR7. I\\'ve been to üá∫üá∏üáÆüáπüá´üá∑üá®üá≠üá≥üá±üá™üá∏üáØüáµ, but I can only speak english and korean. Republic of Korea\"}, {\"url\": \"https://deepai.org/profile/jeong-hoe-ku\", \"content\": \"Read Jeong-Hoe Ku\\'s latest research, browse their coauthor\\'s research, and play around with their algorithms\"}, {\"url\": \"https://github.com/mrku69\", \"content\": \"mrku69 Follow Jeong-Hoe Ku mrku69 Follow Samsung Elec. Co. Ltd. AI Center Principal Engineer 0 followers ¬∑ 5 following Samsung Elec. Block or Report Block or report mrku69\"}, {\"url\": \"https://www.catalyzex.com/author/Jeong-Hoe+Ku\", \"content\": \"View Jeong-Hoe Ku\\'s papers and open-source code. See more researchers and engineers like Jeong-Hoe Ku.\"}, {\"url\": \"https://twitter.com/KoreanLegal_CLS/status/1339319513280634884\", \"content\": \"Center for Korean Legal Studies on Twitter: \\\\\"TONIGHT 7PM EST \\\\\"New Paths or Same Direction? The Prospects for Human Rights and Accountability in North Korea.\\\\\"\"}]', name='tavily_search_results_json', id='291508e5-f0b7-409c-8e9e-29e76c66272f', tool_call_id='call_fwJ4CtcvC7VVW7qNvrzvdcj3', artifact={'query': 'Jeong-Hoe Ku latest tweet', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Ku Jeong-hoon (@kujeonghoon) | Twitter', 'url': 'https://twitter.com/kujeonghoon', 'content': \"The latest Tweets from Ku Jeong-hoon (@kujeonghoon). Gaming nerd, amateur artist, movie maniac, lone traveler, big fan of CR7. I've been to üá∫üá∏üáÆüáπüá´üá∑üá®üá≠üá≥üá±üá™üá∏üáØüáµ, but I can only speak english and korean. Republic of Korea\", 'score': 0.7576693, 'raw_content': None}, {'title': 'Jeong-Hoe Ku - DeepAI', 'url': 'https://deepai.org/profile/jeong-hoe-ku', 'content': \"Read Jeong-Hoe Ku's latest research, browse their coauthor's research, and play around with their algorithms\", 'score': 0.37669244, 'raw_content': None}, {'title': 'mrku69 (Jeong-Hoe Ku) ¬∑ GitHub', 'url': 'https://github.com/mrku69', 'content': 'mrku69 Follow Jeong-Hoe Ku mrku69 Follow Samsung Elec. Co. Ltd. AI Center Principal Engineer 0 followers ¬∑ 5 following Samsung Elec. Block or Report Block or report mrku69', 'score': 0.26623908, 'raw_content': None}, {'title': 'Jeong-Hoe Ku - catalyzex.com', 'url': 'https://www.catalyzex.com/author/Jeong-Hoe+Ku', 'content': \"View Jeong-Hoe Ku's papers and open-source code. See more researchers and engineers like Jeong-Hoe Ku.\", 'score': 0.15384161, 'raw_content': None}, {'title': 'Center for Korean Legal Studies on Twitter', 'url': 'https://twitter.com/KoreanLegal_CLS/status/1339319513280634884', 'content': 'Center for Korean Legal Studies on Twitter: \"TONIGHT 7PM EST \"New Paths or Same Direction? The Prospects for Human Rights and Accountability in North Korea.\"', 'score': 0.14820766, 'raw_content': None}], 'response_time': 1.79}), ToolMessage(content='[{\"url\": \"https://twitter.com/FrioDenziel\", \"content\": \"The latest Tweets from jihun park oh (@FrioDenziel): \\\\\"https://t.co/8R7xj3Flvq @jekoyfries Nakakatawa si kuya Jekoy hahahaüòÇüòÇüòÇüòÇüòÇlove you poüòÇüòòüòòüòÇ\\\\\"\"}, {\"url\": \"https://twitter.com/Repubzihun\", \"content\": \"The latest Tweets from Oh Jihun (@Repubzihun). Homo Empathicus, ÌÅ¨Î¶¨Ïä§Ï≤ú Î≥¥Ìó§ÎØ∏Ïïà, ÏÑ∏Î°úÌÜ†Îãå Ï¢åÌåå, Í∞ïÎèôÏò®ÎàÑÎ¶¨ÍµêÌöå, Ï§ëÏÜåÍ∏∞ÏóÖÏßÑÌù•Í≥µÎã®, Í¥ÄÏã¨ÏÇ¨: ÏÇ¨ÌöåÏ†ïÏã†ÏùòÌïô-ÏûÖÏûêÎ¨ºÎ¶¨Ìïô-Ï≤†Ìïô, ÌÅ¥ÎûòÏãùtoÏùºÎ†âÌä∏Î°úÎãàÏπ¥ ÏùåÏïÖ, Editology?(by ÍπÄÏ†ïÏö¥). South Korea\"}, {\"url\": \"https://twitter.com/jihun_oh_94\", \"content\": \"The latest Tweets from Jigme Wangmo‚ô° (@jihun_oh_94). Music Dance/Electronic. Bhutan\"}, {\"url\": \"https://twitter.com/talkpanda\", \"content\": \"The latest Tweets from Jihun. Oh (@talkpanda). ÏòÅÌôî|ÏÇ¨ÏßÑ|ÏùåÏïÖ|Î™®Î∞îÏùº. Busan,Korea\"}, {\"url\": \"https://opencorporates.com/companies/us_ca/0972354\", \"content\": \"JIHUN OH Agent Address 4371 CERRITOS AVE, CYPRESS, CA, 90630 ... Latest Events. 1980-01-11 Incorporated. 1980-01-11 - 2018-11-30 Addition of officer JIHUN OH, agent. 2021-01-23 - 2021-04-30 ... Twitter; Medium; Newsletter; Problems with our data? Temporary redaction; Impact. Impact;\"}]', name='tavily_search_results_json', id='3cceae49-856a-4964-9cdc-a6e54431dcf6', tool_call_id='call_ilOJnsw1K836cRbs2RVFQIzy', artifact={'query': 'JiHun Oh latest tweet', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'jihun park oh (@FrioDenziel) - Twitter', 'url': 'https://twitter.com/FrioDenziel', 'content': 'The latest Tweets from jihun park oh (@FrioDenziel): \"https://t.co/8R7xj3Flvq @jekoyfries Nakakatawa si kuya Jekoy hahahaüòÇüòÇüòÇüòÇüòÇlove you poüòÇüòòüòòüòÇ\"', 'score': 0.82391036, 'raw_content': None}, {'title': 'Oh Jihun (@Repubzihun) - Twitter', 'url': 'https://twitter.com/Repubzihun', 'content': 'The latest Tweets from Oh Jihun (@Repubzihun). Homo Empathicus, ÌÅ¨Î¶¨Ïä§Ï≤ú Î≥¥Ìó§ÎØ∏Ïïà, ÏÑ∏Î°úÌÜ†Îãå Ï¢åÌåå, Í∞ïÎèôÏò®ÎàÑÎ¶¨ÍµêÌöå, Ï§ëÏÜåÍ∏∞ÏóÖÏßÑÌù•Í≥µÎã®, Í¥ÄÏã¨ÏÇ¨: ÏÇ¨ÌöåÏ†ïÏã†ÏùòÌïô-ÏûÖÏûêÎ¨ºÎ¶¨Ìïô-Ï≤†Ìïô, ÌÅ¥ÎûòÏãùtoÏùºÎ†âÌä∏Î°úÎãàÏπ¥ ÏùåÏïÖ, Editology?(by ÍπÄÏ†ïÏö¥). South Korea', 'score': 0.7927375, 'raw_content': None}, {'title': 'Jigme Wangmo‚ô° (@jihun_oh_94) - Twitter', 'url': 'https://twitter.com/jihun_oh_94', 'content': 'The latest Tweets from Jigme Wangmo‚ô° (@jihun_oh_94). Music Dance/Electronic. Bhutan', 'score': 0.76152116, 'raw_content': None}, {'title': 'Jihun. Oh (@talkpanda) - Twitter', 'url': 'https://twitter.com/talkpanda', 'content': 'The latest Tweets from Jihun. Oh (@talkpanda). ÏòÅÌôî|ÏÇ¨ÏßÑ|ÏùåÏïÖ|Î™®Î∞îÏùº. Busan,Korea', 'score': 0.75442725, 'raw_content': None}, {'title': 'MIRACLE LAND KOREAN BAPTIST CHURCH :: California (US) - OpenCorporates', 'url': 'https://opencorporates.com/companies/us_ca/0972354', 'content': 'JIHUN OH Agent Address 4371 CERRITOS AVE, CYPRESS, CA, 90630 ... Latest Events. 1980-01-11 Incorporated. 1980-01-11 - 2018-11-30 Addition of officer JIHUN OH, agent. 2021-01-23 - 2021-04-30 ... Twitter; Medium; Newsletter; Problems with our data? Temporary redaction; Impact. Impact;', 'score': 0.5550741, 'raw_content': None}], 'response_time': 1.88}), ToolMessage(content='[{\"url\": \"https://twitter.com/SungYoonLee1/status/1633971890564866048\", \"content\": \"See new Tweets. Conversation. Sung-Yoon Lee @SungYoonLee1. Are those slippers he\\'s wearing? 11:23 PM ¬∑ Mar 9, 2023\"}, {\"url\": \"https://twitter.com/theseoulstory/status/1681186080064778240\", \"content\": \"Lee Chan Young (son of singer & producer Yoon Sang) to reportedly join SM\\'s new boy group SM didn\\'t explicitly confirm the rumour. They only said, details regarding the new boy group will be unveiled on August 1 Lee previously lived in New Jersey where he was active as swimmer . 18 Jul 2023 06:16:11\"}, {\"url\": \"https://www.cardplayer.com/poker-players/472594-youngyoon-lee\", \"content\": \"Youngyoon Lee poker results, stats, photos, videos, news, magazine columns, blogs, Twitter, and more.\"}, {\"url\": \"https://www.idcrawl.com/young-yoon\", \"content\": \"Found 1974 people named Young Yoon. Instagram, Twitter, Facebook, TikTok profiles, and images on IDCrawl - free people search. Looking for Young Yoon? Found 1974 people named Young Yoon. ... Is Lee Yoo-Young Jealous of the New Woman in Kim Myung-Soo\\'s Life? ComingSoon.net - Tue, 28 May 2024 . Sweet Home Season 2 Cast: All 10 Main Actors Who\"}, {\"url\": \"https://www.linkedin.com/in/young-yoon--lee\", \"content\": \"Young-Yoon Lee received the B.S. (summa cum laude) in electrical engineering and Ph.D‚Ä¶ ¬∑ Experience: Roblox ¬∑ Education: Stanford University ¬∑ Location: San Mateo ¬∑ 500+ connections on LinkedIn.\"}]', name='tavily_search_results_json', id='a81f4c24-905f-4895-a620-2bdfcce675ca', tool_call_id='call_Uu7PcfLMixxKayaPEv6QeMdE', artifact={'query': 'YoungYoon Lee latest tweet', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Sung-Yoon Lee on Twitter', 'url': 'https://twitter.com/SungYoonLee1/status/1633971890564866048', 'content': \"See new Tweets. Conversation. Sung-Yoon Lee @SungYoonLee1. Are those slippers he's wearing? 11:23 PM ¬∑ Mar 9, 2023\", 'score': 0.5255399, 'raw_content': None}, {'title': 'The Seoul Story on Twitter: \"Lee Chan Young (son of singer & producer ...', 'url': 'https://twitter.com/theseoulstory/status/1681186080064778240', 'content': \"Lee Chan Young (son of singer & producer Yoon Sang) to reportedly join SM's new boy group SM didn't explicitly confirm the rumour. They only said, details regarding the new boy group will be unveiled on August 1 Lee previously lived in New Jersey where he was active as swimmer . 18 Jul 2023 06:16:11\", 'score': 0.4395795, 'raw_content': None}, {'title': 'Youngyoon Lee - Poker Player - CardPlayer.com', 'url': 'https://www.cardplayer.com/poker-players/472594-youngyoon-lee', 'content': 'Youngyoon Lee poker results, stats, photos, videos, news, magazine columns, blogs, Twitter, and more.', 'score': 0.37339646, 'raw_content': None}, {'title': \"Young Yoon's Instagram, Twitter & Facebook on IDCrawl\", 'url': 'https://www.idcrawl.com/young-yoon', 'content': \"Found 1974 people named Young Yoon. Instagram, Twitter, Facebook, TikTok profiles, and images on IDCrawl - free people search. Looking for Young Yoon? Found 1974 people named Young Yoon. ... Is Lee Yoo-Young Jealous of the New Woman in Kim Myung-Soo's Life? ComingSoon.net - Tue, 28 May 2024 . Sweet Home Season 2 Cast: All 10 Main Actors Who\", 'score': 0.33770624, 'raw_content': None}, {'title': 'Young Yoon Lee - Roblox - LinkedIn', 'url': 'https://www.linkedin.com/in/young-yoon--lee', 'content': 'Young-Yoon Lee received the B.S. (summa cum laude) in electrical engineering and Ph.D‚Ä¶ ¬∑ Experience: Roblox ¬∑ Education: Stanford University ¬∑ Location: San Mateo ¬∑ 500+ connections on LinkedIn.', 'score': 0.293572, 'raw_content': None}], 'response_time': 1.94}), ToolMessage(content='[{\"url\": \"https://www.linkedin.com/posts/gaurav-pooniwala_generative-ai-is-unfurling-a-creative-new-activity-7034471873702727680-yS_Q\", \"content\": \"Check out our latest company blog on Generative AI and Creativity! ... Gaurav Pooniwala\\'s Post ... Twitter; To view or add a comment,\"}, {\"url\": \"https://deepai.org/profile/gaurav-pooniwala\", \"content\": \"Read Gaurav Pooniwala\\'s latest research, browse their coauthor\\'s research, and play around with their algorithms ... Hey Gaurav Pooniwala! Claim your profile and join one of the world\\'s largest A.I. communities. claim Claim with Google Claim with Twitter Claim with GitHub Claim with LinkedIn.\"}, {\"url\": \"https://www.instagram.com/rephraseai/p/CfbswelPR2P/\", \"content\": \"51 likes, 2 comments - rephraseai on June 30, 2022: \\\\\"Meet Gaurav Pooniwala who works in the Deep Tech team at Rephrase.ai. Guarav says \\\\\"AI was an exci...\\\\\" Rephrase.ai on Instagram: \\\\\"Meet Gaurav Pooniwala who works in the Deep Tech team at Rephrase.ai.\"}, {\"url\": \"https://www.clearadmit.com/2023/11/real-humans-of-the-london-business-school-mba-class-of-2025/3/\", \"content\": \"Gaurav Pooniwala, London Business School\\'s MBA Class of 2025. Age: 30 Hometown: Mumbai, India Undergraduate Institution and Major: IIT Bombay, BTech in Electrical Engineering Pre-MBA Work Experience (role, company, years): Deep Learning Engineer/Consultant, Samsung Electronics, Seoul, 6 years; Senior AI Engineer, Rephrase Technologies, 2 years; Technical Crisis Manager, Rephrase Technology\"}, {\"url\": \"https://www.linkedin.com/posts/gaurav-pooniwala_marketinginnovation-aiinbusiness-ai-activity-7157534657985585152-HgXs\", \"content\": \"Excited to announce that my pre-MBA project at Rephrase.ai \\\\\"Not Just a Cadbury Ad\\\\\" featuring Shah Rukh Khan, took center stage in a recent Marketing class at‚Ä¶\"}]', name='tavily_search_results_json', id='b976692f-6d5c-4c69-bd81-10e2c5387bc8', tool_call_id='call_1xVieiE7t3Pkw74jrQyaWsxr', artifact={'query': 'Gaurav Pooniwala latest tweet', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': \"Gaurav Pooniwala's Post - LinkedIn\", 'url': 'https://www.linkedin.com/posts/gaurav-pooniwala_generative-ai-is-unfurling-a-creative-new-activity-7034471873702727680-yS_Q', 'content': \"Check out our latest company blog on Generative AI and Creativity! ... Gaurav Pooniwala's Post ... Twitter; To view or add a comment,\", 'score': 0.57437146, 'raw_content': None}, {'title': 'Gaurav Pooniwala - DeepAI', 'url': 'https://deepai.org/profile/gaurav-pooniwala', 'content': \"Read Gaurav Pooniwala's latest research, browse their coauthor's research, and play around with their algorithms ... Hey Gaurav Pooniwala! Claim your profile and join one of the world's largest A.I. communities. claim Claim with Google Claim with Twitter Claim with GitHub Claim with LinkedIn.\", 'score': 0.5709301, 'raw_content': None}, {'title': 'Rephrase.ai on Instagram: \"Meet Gaurav Pooniwala who works in the Deep ...', 'url': 'https://www.instagram.com/rephraseai/p/CfbswelPR2P/', 'content': '51 likes, 2 comments - rephraseai on June 30, 2022: \"Meet Gaurav Pooniwala who works in the Deep Tech team at Rephrase.ai. Guarav says \"AI was an exci...\" Rephrase.ai on Instagram: \"Meet Gaurav Pooniwala who works in the Deep Tech team at Rephrase.ai.', 'score': 0.5255399, 'raw_content': None}, {'title': 'Real Humans of the London Business School MBA Class of 2025', 'url': 'https://www.clearadmit.com/2023/11/real-humans-of-the-london-business-school-mba-class-of-2025/3/', 'content': \"Gaurav Pooniwala, London Business School's MBA Class of 2025. Age: 30 Hometown: Mumbai, India Undergraduate Institution and Major: IIT Bombay, BTech in Electrical Engineering Pre-MBA Work Experience (role, company, years): Deep Learning Engineer/Consultant, Samsung Electronics, Seoul, 6 years; Senior AI Engineer, Rephrase Technologies, 2 years; Technical Crisis Manager, Rephrase Technology\", 'score': 0.51325434, 'raw_content': None}, {'title': \"Gaurav Pooniwala's Post - LinkedIn\", 'url': 'https://www.linkedin.com/posts/gaurav-pooniwala_marketinginnovation-aiinbusiness-ai-activity-7157534657985585152-HgXs', 'content': 'Excited to announce that my pre-MBA project at Rephrase.ai \"Not Just a Cadbury Ad\" featuring Shah Rukh Khan, took center stage in a recent Marketing class at‚Ä¶', 'score': 0.44796792, 'raw_content': None}], 'response_time': 1.62}), ToolMessage(content='[{\"url\": \"https://twitter.com/sound0817\", \"content\": \"The latest Tweets from Sang Jeong Lee (@sound0817). ÍµêÌöåÏùåÌñ•/ÏùåÌñ•ÏóîÏßÄÎãàÏñ¥/ÏùåÌñ•Î†åÌÉà/ÏùåÌñ•ÏãúÍ≥µ/Ï∫êÎÖº400d/ÏàúÎ≥µÏùåÏõêÎãπÍµêÌöå/Ï≤≠ÎÖÑÎ∂Ä/Ï∞¨Ïñë\"}, {\"url\": \"https://twitter.com/SangJoonSJLee\", \"content\": \"The latest Tweets from Sang-Joon Lee (@SangJoonSJLee). Systems, Software Engineer. Toronto, Boston\"}, {\"url\": \"https://twitter.com/lsjeong\", \"content\": \"Sign up. See new Tweets\"}, {\"url\": \"https://www.instagram.com/tree_eye_potter/\", \"content\": \"494 Followers, 842 Following, 330 Posts - Sang-Jeong Lee (@tree_eye_potter) on Instagram: \\\\\"Ceramic artist based in Boston, MA \\\\\"\"}, {\"url\": \"https://www.reddit.com/r/koreanvariety/comments/1c7mejy/transit_love_3_exchange_3_e20_end_240419/\", \"content\": \"Now, having regained you, Sang-jeong, all these trials and hardships have transformed into memories! Sangjeong (This was posted with MH in it ) ‚ô• Thank you so much to all the viewers who loved \\'Transit Love Season 3\\'!\"}]', name='tavily_search_results_json', id='efa9725c-0fc6-48ff-8f36-87157b745c77', tool_call_id='call_QbYiJ0qetlchNIAPT346LP7t', artifact={'query': 'SangJeong Lee latest tweet', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Sang Jeong Lee (@sound0817) - Twitter', 'url': 'https://twitter.com/sound0817', 'content': 'The latest Tweets from Sang Jeong Lee (@sound0817). ÍµêÌöåÏùåÌñ•/ÏùåÌñ•ÏóîÏßÄÎãàÏñ¥/ÏùåÌñ•Î†åÌÉà/ÏùåÌñ•ÏãúÍ≥µ/Ï∫êÎÖº400d/ÏàúÎ≥µÏùåÏõêÎãπÍµêÌöå/Ï≤≠ÎÖÑÎ∂Ä/Ï∞¨Ïñë', 'score': 0.84858394, 'raw_content': None}, {'title': 'Sang-Joon Lee (@SangJoonSJLee) - Twitter', 'url': 'https://twitter.com/SangJoonSJLee', 'content': 'The latest Tweets from Sang-Joon Lee (@SangJoonSJLee). Systems, Software Engineer. Toronto, Boston', 'score': 0.73138535, 'raw_content': None}, {'title': 'Sang-Jeong,Lee (@lsjeong) / Twitter', 'url': 'https://twitter.com/lsjeong', 'content': 'Sign up. See new Tweets', 'score': 0.5843666, 'raw_content': None}, {'title': 'Sang-Jeong Lee (@tree_eye_potter) ‚Ä¢ Instagram photos and videos', 'url': 'https://www.instagram.com/tree_eye_potter/', 'content': '494 Followers, 842 Following, 330 Posts - Sang-Jeong Lee (@tree_eye_potter) on Instagram: \"Ceramic artist based in Boston, MA \"', 'score': 0.5465209, 'raw_content': None}, {'title': 'Transit Love 3 (EXchange 3) | E20 END | 240419 : r/koreanvariety - Reddit', 'url': 'https://www.reddit.com/r/koreanvariety/comments/1c7mejy/transit_love_3_exchange_3_e20_end_240419/', 'content': \"Now, having regained you, Sang-jeong, all these trials and hardships have transformed into memories! Sangjeong (This was posted with MH in it ) ‚ô• Thank you so much to all the viewers who loved 'Transit Love Season 3'!\", 'score': 0.5040288, 'raw_content': None}], 'response_time': 3.43})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content=\"Here are the latest tweets or social media profiles for the authors of the Knowledge Distillation papers:\\n\\n1. **Minghong Gao**: No specific tweet found, but you can check [Minghong Gao's Threads profile](https://www.threads.net/@minghong.gao) for the latest updates.\\n\\n2. **Jie Song**: Multiple profiles found, but you can check [Jie Song's Twitter profile](https://twitter.com/JieSong95) for the latest tweets.\\n\\n3. **Ying Chen**: Check [Ying Chen's Twitter profile](https://twitter.com/YingChen160722) for the latest tweets.\\n\\n4. **Jingwen Ye**: Check [Jingwen Ye's Twitter profile](https://twitter.com/jingwenjw) for the latest tweets.\\n\\n5. **Mingli Song**: Check [Mingli Song's Twitter profile](https://twitter.com/mingli_song) for the latest tweets.\\n\\n6. **Jeong-Hoe Ku**: Check [Jeong-Hoe Ku's Twitter profile](https://twitter.com/kujeonghoon) for the latest tweets.\\n\\n7. **JiHun Oh**: Check [JiHun Oh's Twitter profile](https://twitter.com/FrioDenziel) for the latest tweets.\\n\\n8. **YoungYoon Lee**: No specific tweet found, but you can explore [YoungYoon Lee's LinkedIn profile](https://www.linkedin.com/in/young-yoon--lee) for more information.\\n\\n9. **Gaurav Pooniwala**: No specific tweet found, but you can explore [Gaurav Pooniwala's LinkedIn profile](https://www.linkedin.com/posts/gaurav-pooniwala_marketinginnovation-aiinbusiness-ai-activity-7157534657985585152-HgXs) for more information.\\n\\n10. **SangJeong Lee**: Check [Sang Jeong Lee's Twitter profile](https://twitter.com/sound0817) for the latest tweets.\\n\\nPlease note that some authors may not have a public Twitter account or recent tweets available.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 440, 'prompt_tokens': 5004, 'total_tokens': 5444, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1152}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'stop', 'logprobs': None}, id='run-434335cd-fe9f-4c01-8e8f-253b32fe90ca-0', usage_metadata={'input_tokens': 5004, 'output_tokens': 440, 'total_tokens': 5444, 'input_token_details': {'audio': 0, 'cache_read': 1152}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####üèóÔ∏è Activity #2:\n",
        "\n",
        "Please write out the steps the agent took to arrive at the correct answer.\n",
        "\n",
        "1. Human Message is passed on to the graph, and the state object is populated.\n",
        "2. The State is passed to the Agent Node, which based on the user input, makes a tool call to Arxiv.\n",
        "3. Action is performed to retrieve Authors related to Active Learning.\n",
        "4. Message is passed to the Agent, which now decides to use the Tavily Tool, to search for Tweets by these authors.\n",
        "5. An Action is prformed to call Tavily Search Results JSON function to retrieve the Tweets.\n",
        "6. The retrieved tweets are then displayed to the user by the Agent"
      ],
      "metadata": {
        "id": "CXzDlZVz1Hnf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uyV1hqhVwyZM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: LangSmith Evaluator"
      ],
      "metadata": {
        "id": "v7c8-Uyarh1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre-processing for LangSmith"
      ],
      "metadata": {
        "id": "pV3XeFOT1Sar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To do a little bit more preprocessing, let's wrap our LangGraph agent in a simple chain."
      ],
      "metadata": {
        "id": "wruQCuzewUuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_inputs(input_object):\n",
        "  return {\"messages\" : [HumanMessage(content=input_object[\"question\"])]}\n",
        "\n",
        "def parse_output(input_state):\n",
        "  return input_state[\"messages\"][-1].content\n",
        "\n",
        "agent_chain = convert_inputs | compiled_graph | parse_output"
      ],
      "metadata": {
        "id": "oeXdQgbxwhTv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.invoke({\"question\" : \"What is RAG?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "orYxBZXSxJjZ",
        "outputId": "7a6597aa-2329-485e-ba65-7d0f798a0738"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"RAG stands for Retrieval-Augmented Generation. It is a technique used in natural language processing (NLP) that combines retrieval-based methods with generative models to improve the quality and accuracy of generated text. Here's a brief overview of how it works:\\n\\n1. **Retrieval**: In the first step, relevant documents or pieces of information are retrieved from a large corpus or database. This is typically done using a retrieval model that identifies the most relevant documents based on the input query.\\n\\n2. **Augmentation**: The retrieved documents are then used to augment the input query. This means that the information from the retrieved documents is combined with the original query to provide more context and background information.\\n\\n3. **Generation**: Finally, a generative model, such as a transformer-based language model, uses the augmented input to generate a response or answer. The generative model can produce more accurate and contextually relevant responses because it has access to additional information from the retrieval step.\\n\\nRAG is particularly useful in scenarios where the model needs to generate responses based on a large and diverse set of information, such as in open-domain question answering or conversational AI systems. By leveraging both retrieval and generation, RAG can produce more informed and contextually appropriate outputs.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1: Creating An Evaluation Dataset\n",
        "\n",
        "Just as we saw last week, we'll want to create a dataset to test our Agent's ability to answer questions.\n",
        "\n",
        "In order to do this - we'll want to provide some questions and some answers. Let's look at how we can create such a dataset below.\n",
        "\n",
        "```python\n",
        "questions = [\n",
        "    \"What optimizer is used in QLoRA?\",\n",
        "    \"What data type was created in the QLoRA paper?\",\n",
        "    \"What is a Retrieval Augmented Generation system?\",\n",
        "    \"Who authored the QLoRA paper?\",\n",
        "    \"What is the most popular deep learning framework?\",\n",
        "    \"What significant improvements does the LoRA system make?\"\n",
        "]\n",
        "\n",
        "answers = [\n",
        "    {\"must_mention\" : [\"paged\", \"optimizer\"]},\n",
        "    {\"must_mention\" : [\"NF4\", \"NormalFloat\"]},\n",
        "    {\"must_mention\" : [\"ground\", \"context\"]},\n",
        "    {\"must_mention\" : [\"Tim\", \"Dettmers\"]},\n",
        "    {\"must_mention\" : [\"PyTorch\", \"TensorFlow\"]},\n",
        "    {\"must_mention\" : [\"reduce\", \"parameters\"]},\n",
        "]\n",
        "```"
      ],
      "metadata": {
        "id": "f9UkCIqkpyZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####üèóÔ∏è Activity #3:\n",
        "\n",
        "Please create a dataset in the above format with at least 5 questions."
      ],
      "metadata": {
        "id": "VfMXF2KAsQxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"What is Active Learning in Machine Learning?\",\n",
        "    \"who is the author of Harry Potter ?\",\n",
        "    \"Who is the prime minister of India ?\",\n",
        "    \"Where are the Kiwi animal found ?\"\n",
        "]\n",
        "\n",
        "answers = [\n",
        "        {\"must_mention\" : [\"continous\", \"adapt\"]},\n",
        "        {\"must_mention\" : [\"JK Rowling\"]},\n",
        "        {\"must_mention\" : [\"Narendra Modi\"]},\n",
        "        {\"must_mention\" : [\"New Zealand\"]}\n",
        "\n",
        "\n",
        "    ### YOUR CODE HERE\n",
        "]"
      ],
      "metadata": {
        "id": "CbagRuJop83E"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can add our dataset to our LangSmith project using the following code which we saw last Thursday!"
      ],
      "metadata": {
        "id": "z7QVFuAmsh7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()\n",
        "\n",
        "dataset_name = f\"Retrieval Augmented Generation - Evaluation Dataset - {uuid4().hex[0:8]}\"\n",
        "\n",
        "dataset = client.create_dataset(\n",
        "    dataset_name=dataset_name,\n",
        "    description=\"Questions about the QLoRA Paper to Evaluate RAG over the same paper.\"\n",
        ")\n",
        "\n",
        "client.create_examples(\n",
        "    inputs=[{\"question\" : q} for q in questions],\n",
        "    outputs=answers,\n",
        "    dataset_id=dataset.id,\n",
        ")"
      ],
      "metadata": {
        "id": "RLfrZrgSsn85"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ‚ùì Question #3:\n",
        "\n",
        "How are the correct answers associated with the questions?\n",
        "\n",
        "IN this case it relies on the must have function we defined, it does a key word search based on Q/A Pairs, its problematic as it does not consider the context, and does an exact match\n",
        "\n",
        "> NOTE: Feel free to indicate if this is problematic or not"
      ],
      "metadata": {
        "id": "ciV73F9Q04w0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2: Adding Evaluators\n",
        "\n",
        "Now we can add a custom evaluator to see if our responses contain the expected information.\n",
        "\n",
        "We'll be using a fairly naive exact-match process to determine if our response contains specific strings."
      ],
      "metadata": {
        "id": "-lRTXUrTtP9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langsmith.evaluation import EvaluationResult, run_evaluator\n",
        "\n",
        "@run_evaluator\n",
        "def must_mention(run, example) -> EvaluationResult:\n",
        "    prediction = run.outputs.get(\"output\") or \"\"\n",
        "    required = example.outputs.get(\"must_mention\") or []\n",
        "    score = all(phrase in prediction for phrase in required)\n",
        "    return EvaluationResult(key=\"must_mention\", score=score)"
      ],
      "metadata": {
        "id": "QrAUXMFftlAY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ‚ùì Question #4:\n",
        "\n",
        "What are some ways you could improve this metric as-is?\n",
        "\n",
        "1. This metric does a key word search and would yield a poor result due to the vastness of the vocab, It is also case sensitive and requires that all word be present in the must have dictionary for the evaluation to pass.\n",
        "\n",
        "2. We can overcome these limiations by implementing a evaluator which looks at semantic similarity between retrieved results and sample response.\n",
        "\n",
        "> NOTE: Alternatively you can suggest where gaps exist in this method."
      ],
      "metadata": {
        "id": "PNtHORUh0jZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3: Evaluating\n",
        "\n",
        "All that is left to do is evaluate our agent's response!"
      ],
      "metadata": {
        "id": "r1RJr349zhv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for Semantic Evaluator\n",
        "@run_evaluator\n",
        "def must_mention(run, example) -> EvaluationResult:\n",
        "    prediction = run.outputs.get(\"output\") or \"\"\n",
        "    required_phrases = example.outputs.get(\"must_mention\") or []\n",
        "\n",
        "    if not required_phrases:\n",
        "        return EvaluationResult(key=\"must_mention\", score=1.0)\n",
        "\n",
        "    # Compute similarity scores\n",
        "    pred_embedding = model.encode(prediction, convert_to_tensor=True)\n",
        "    required_embeddings = model.encode(required_phrases, convert_to_tensor=True)\n",
        "\n",
        "    # Check if any required phrase is semantically present in the prediction\n",
        "    scores = [util.pytorch_cos_sim(pred_embedding, req_emb).item() for req_emb in required_embeddings]\n",
        "    threshold = 0.6\n",
        "    score = all(sim >= threshold for sim in scores)\n",
        "\n",
        "    return EvaluationResult(key=\"must_mention\", score=score)\n"
      ],
      "metadata": {
        "id": "L8S-HgHmyV3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_results = client.evaluate(\n",
        "    agent_chain,\n",
        "    data=dataset_name,\n",
        "    evaluators=[must_mention],\n",
        "    experiment_prefix=f\"RAG Pipeline - Evaluation - {uuid4().hex[0:4]}\",\n",
        "    metadata={\"version\": \"1.0.0\"},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "90ca81bde4b7409b8ad0408350d3dacc",
            "ba34c40da915427c97a35365a74ed548",
            "12594fdddafe48c38e224beb97b24a7b",
            "a4c0da2829704de79223aa84af932e0f",
            "6fc846aafd16460eade00e3d087b1547",
            "d1a2fa24d58e4f0084d9db755bb59e01",
            "b34ee74919bd40919e51d171464824b0",
            "66134ba838604465bbac92a48edfc5a5",
            "032c5ecba2614c7da37859cee77dd470",
            "492f964ab41d46c58933cec0cf627d8a",
            "4fba9013a3364ce490fbec88334806c9"
          ]
        },
        "id": "p5TeCUUkuGld",
        "outputId": "baa7bee6-2964-410b-c188-7a8fa1eb128b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View the evaluation results for experiment: 'RAG Pipeline - Evaluation - 5661-2df073f7' at:\n",
            "https://smith.langchain.com/o/0f68779b-4f33-4cff-b90c-c04c816f8d27/datasets/77eb0023-af6b-43c9-81d9-1b12eecf0244/compare?selectedSessions=18e8e9af-dec8-4c57-84bf-5c1b20f8f7b0\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90ca81bde4b7409b8ad0408350d3dacc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "eeEqU7s05Byu",
        "outputId": "07cde4df-656f-4209-91b0-49a9fe8610b3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<ExperimentResults RAG Pipeline - Evaluation - 5661-2df073f7>"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs.question</th>\n",
              "      <th>outputs.output</th>\n",
              "      <th>error</th>\n",
              "      <th>reference.must_mention</th>\n",
              "      <th>feedback.must_mention</th>\n",
              "      <th>execution_time</th>\n",
              "      <th>example_id</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Where are the Kiwi animal found ?</td>\n",
              "      <td>Kiwi birds are native to New Zealand. They are...</td>\n",
              "      <td>None</td>\n",
              "      <td>[New Zealand]</td>\n",
              "      <td>True</td>\n",
              "      <td>3.212741</td>\n",
              "      <td>34a4246b-4ecc-4abe-9247-e0688449b612</td>\n",
              "      <td>788e36d6-024b-4167-b001-31b4de487a85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who is the prime minister of India ?</td>\n",
              "      <td>The Prime Minister of India is Narendra Modi. ...</td>\n",
              "      <td>None</td>\n",
              "      <td>[Narendra Modi]</td>\n",
              "      <td>True</td>\n",
              "      <td>1.974969</td>\n",
              "      <td>b461ac6d-8ec8-469c-b236-8ff725b7fdf3</td>\n",
              "      <td>74d53daf-2143-466b-9b10-0e0b2d6f481c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>who is the author of Harry Potter ?</td>\n",
              "      <td>The author of the Harry Potter series is J.K. ...</td>\n",
              "      <td>None</td>\n",
              "      <td>[JK Rowling]</td>\n",
              "      <td>False</td>\n",
              "      <td>4.631438</td>\n",
              "      <td>b84295d6-b7ce-4875-9eda-fe34ab31cd99</td>\n",
              "      <td>80a4b541-d6d7-4c4a-b32b-78e5dd42b376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is Active Learning in Machine Learning?</td>\n",
              "      <td>Active learning is a subfield of machine learn...</td>\n",
              "      <td>None</td>\n",
              "      <td>[continous, adapt]</td>\n",
              "      <td>False</td>\n",
              "      <td>5.974095</td>\n",
              "      <td>a3123c5b-c460-4f1b-80af-cef84648f25d</td>\n",
              "      <td>bea25268-8f72-49de-bc5e-47aec6011308</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: LangGraph with Helpfulness:"
      ],
      "metadata": {
        "id": "jhTNe4kWrplB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3: Adding Helpfulness Check and \"Loop\" Limits\n",
        "\n",
        "Now that we've done evaluation - let's see if we can add an extra step where we review the content we've generated to confirm if it fully answers the user's query!\n",
        "\n",
        "We're going to make a few key adjustments to account for this:\n",
        "\n",
        "1. We're going to add an artificial limit on how many \"loops\" the agent can go through - this will help us to avoid the potential situation where we never exit the loop.\n",
        "2. We'll add to our existing conditional edge to obtain the behaviour we desire."
      ],
      "metadata": {
        "id": "w1wKRddbIY_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's define our state again - we can check the length of the state object, so we don't need additional state for this."
      ],
      "metadata": {
        "id": "npTYJ8ayR5B3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[list, add_messages]"
      ],
      "metadata": {
        "id": "-LQ84YhyJG0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can set our graph up! This process will be almost entirely the same - with the inclusion of one additional node/conditional edge!"
      ],
      "metadata": {
        "id": "sD7EV0HqSQcb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####üèóÔ∏è Activity #5:\n",
        "\n",
        "Please write markdown for the following cells to explain what each is doing."
      ],
      "metadata": {
        "id": "oajBwLkFVi1N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### YOUR MARKDOWN HERE"
      ],
      "metadata": {
        "id": "M6rN7feNVn9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing a State Graph with Agent State which allows us to pass Annonated Message\n",
        "graph_with_helpfulness_check = StateGraph(AgentState)\n",
        "# Adding a node for Agent which allows us to pass message and Invoke a tool based on that\n",
        "graph_with_helpfulness_check.add_node(\"agent\", call_model)\n",
        "# Creating an Action Node, which is essentially a tool which an agent can act upon\n",
        "graph_with_helpfulness_check.add_node(\"action\", tool_node)"
      ],
      "metadata": {
        "id": "6r6XXA5FJbVf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff713041-e498-4f0f-a875-a03502b87729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7cff65caab50>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### YOUR MARKDOWN HERE"
      ],
      "metadata": {
        "id": "XZ22o2mWVrfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We are basically setting the Entry point for our graph to be the Agent Node.\n",
        "graph_with_helpfulness_check.set_entry_point(\"agent\")"
      ],
      "metadata": {
        "id": "HNWHwWxuRiLY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "295f5a35-ceff-452a-ffb8-c52eada6a816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7cff65caab50>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### YOUR MARKDOWN HERE"
      ],
      "metadata": {
        "id": "rsXeF6xlaXOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def tool_call_or_helpful(state):\n",
        "  # Recieve the Latest State Message\n",
        "  last_message = state[\"messages\"][-1]\n",
        "  # Check if a tool call is invoked\n",
        "  if last_message.tool_calls:\n",
        "    # Change the State to Action\n",
        "    return \"action\"\n",
        "  # Just setting initial and final response from the State messages\n",
        "  initial_query = state[\"messages\"][0]\n",
        "  final_response = state[\"messages\"][-1]\n",
        "  # So that we do not end in endless loop, we are limiting the No. of steps to 10\n",
        "  if len(state[\"messages\"]) > 10:\n",
        "    return \"END\"\n",
        "\n",
        "  # Prompt Template\n",
        "  prompt_template = \"\"\"\\\n",
        "  Given an initial query and a final response, determine if the final response is extremely helpful or not. Please indicate helpfulness with a 'Y' and unhelpfulness as an 'N'.\n",
        "\n",
        "  Initial Query:\n",
        "  {initial_query}\n",
        "\n",
        "  Final Response:\n",
        "  {final_response}\"\"\"\n",
        "  # Build Prompt Template\n",
        "  prompt_template = PromptTemplate.from_template(prompt_template)\n",
        "  # Set the LLM model, we need a powerful mode here\n",
        "  helpfulness_check_model = ChatOpenAI(model=\"gpt-4\")\n",
        "  # Create the Chain\n",
        "  helpfulness_chain = prompt_template | helpfulness_check_model | StrOutputParser()\n",
        "  # Invoke the chain\n",
        "  helpfulness_response = helpfulness_chain.invoke({\"initial_query\" : initial_query.content, \"final_response\" : final_response.content})\n",
        "  # If Helpful Response is recieved End the Flow\n",
        "  if \"Y\" in helpfulness_response:\n",
        "    return \"end\"\n",
        "  else:\n",
        "    # Continue until you get helpful response\n",
        "    return \"continue\""
      ],
      "metadata": {
        "id": "z_Sq3A9SaV1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####üèóÔ∏è Activity #4:\n",
        "\n",
        "Please write what is happening in our `tool_call_or_helpful` function!\n",
        "\n",
        "\n",
        "Checks first if a call to an action is made, if not then it builds a LCEL chain to get helpful response based on user query, if N steps > 10 then we exit. Continue until helpful response is received."
      ],
      "metadata": {
        "id": "Fz1u9Vf4SHxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### YOUR MARKDOWN HERE"
      ],
      "metadata": {
        "id": "6BhnBW2YVsJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates a conditional edge, if tool call or helpful returns continue invoke agent again, if it returns action\n",
        "# then perform an action, if it returns end the flow.\n",
        "graph_with_helpfulness_check.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    tool_call_or_helpful,\n",
        "    {\n",
        "        \"continue\" : \"agent\",\n",
        "        \"action\" : \"action\",\n",
        "        \"end\" : END\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "aVTKnWMbP_8T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f729b1f-311c-4084-ceaf-0da437900c85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7cff65caab50>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### YOUR MARKDOWN HERE"
      ],
      "metadata": {
        "id": "ZGDLEWOIVtK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph_with_helpfulness_check.add_edge(\"action\", \"agent\")"
      ],
      "metadata": {
        "id": "cbDK2MbuREgU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a64c20-27a1-4e0e-afde-a639abaa8b55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7cff65caab50>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### YOUR MARKDOWN HERE"
      ],
      "metadata": {
        "id": "rSI8AOaEVvT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_with_helpfulness_check = graph_with_helpfulness_check.compile()"
      ],
      "metadata": {
        "id": "oQldl8ERQ8lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### YOUR MARKDOWN HERE"
      ],
      "metadata": {
        "id": "F67FGCMRVwGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\"messages\" : [HumanMessage(content=\"Related to machine learning, what is LoRA? Also, who is Tim Dettmers? Also, what is Attention?\")]}\n",
        "\n",
        "async for chunk in agent_with_helpfulness_check.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        print(values[\"messages\"])\n",
        "        print(\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3oo8E-PRK1T",
        "outputId": "f152dea8-96ad-4d29-d8b2-a064c96a8bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_5RusS9a5OTBrpXAMZlItuNAo', 'function': {'arguments': '{\"query\": \"LoRA in machine learning\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_YpZhFwpieKG7MeduXwOXbcZY', 'function': {'arguments': '{\"query\": \"Tim Dettmers\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_4RLFT3RVwqOjGij6gXccysq1', 'function': {'arguments': '{\"query\": \"Attention in machine learning\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 81, 'prompt_tokens': 177, 'total_tokens': 258, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-475daa87-692f-42ea-bad5-09a183e02148-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'LoRA in machine learning'}, 'id': 'call_5RusS9a5OTBrpXAMZlItuNAo', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Tim Dettmers'}, 'id': 'call_YpZhFwpieKG7MeduXwOXbcZY', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Attention in machine learning'}, 'id': 'call_4RLFT3RVwqOjGij6gXccysq1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 177, 'output_tokens': 81, 'total_tokens': 258, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "[ToolMessage(content='[{\"url\": \"https://www.cloudflare.com/learning/ai/what-is-lora/\", \"content\": \"LoRA helps make huge and complicated machine learning models much more suited for specific uses. It works by adding lightweight pieces to the original model, as opposed to changing the entire model. LoRA helps developers quickly expand the use cases for the machine learning models they build.\"}, {\"url\": \"https://www.datacamp.com/tutorial/mastering-low-rank-adaptation-lora-enhancing-large-language-models-for-efficient-adaptation\", \"content\": \"LoRA (Low-Rank Adaptation) is a method that reduces the trainable parameters and GPU memory requirements of large language models like GPT-3 by adding small, changeable parts to each layer. Learn how LoRA works, why it is useful, and how to apply it in practice.\"}, {\"url\": \"https://arxiv.org/abs/2106.09685\", \"content\": \"cs arXiv:2106.09685 LoRA: Low-Rank Adaptation of Large Language Models Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. Subjects:   Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) Cite as:    arXiv:2106.09685 [cs.CL] (or arXiv:2106.09685v2 [cs.CL] for this version) cs Bibliographic and Citation Tools Connected Papers Toggle\"}, {\"url\": \"https://medium.com/@alexmriggio/lora-low-rank-adaptation-from-scratch-code-and-theory-f31509106650\", \"content\": \"And that is the aim of LoRA ‚Äî to take the change-in-weight matrix and approximate it with the product of two lower-rank matrices. ... Machine Learning. Lora----1. Follow. Written by AR.\"}, {\"url\": \"https://medium.com/@sandha.iitr/fine-tuning-deep-learning-models-with-low-rank-adaptation-lora-using-google-colab-dac1b4516f71\", \"content\": \"Through LORA_Playground, we aim to provide a practical and insightful resource for the machine learning community, empowering researchers and practitioners to leverage the full potential of LORA\"}]', name='tavily_search_results_json', id='8d9bb40e-2f3e-401c-9ad4-768bd17482c4', tool_call_id='call_5RusS9a5OTBrpXAMZlItuNAo', artifact={'query': 'LoRA in machine learning', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'What is LoRA? | Low-rank adaptation - Cloudflare', 'url': 'https://www.cloudflare.com/learning/ai/what-is-lora/', 'content': 'LoRA helps make huge and complicated machine learning models much more suited for specific uses. It works by adding lightweight pieces to the original model, as opposed to changing the entire model. LoRA helps developers quickly expand the use cases for the machine learning models they build.', 'score': 0.90810597, 'raw_content': None}, {'title': 'Mastering Low-Rank Adaptation (LoRA): Enhancing Large ... - DataCamp', 'url': 'https://www.datacamp.com/tutorial/mastering-low-rank-adaptation-lora-enhancing-large-language-models-for-efficient-adaptation', 'content': 'LoRA (Low-Rank Adaptation) is a method that reduces the trainable parameters and GPU memory requirements of large language models like GPT-3 by adding small, changeable parts to each layer. Learn how LoRA works, why it is useful, and how to apply it in practice.', 'score': 0.87166095, 'raw_content': None}, {'title': '[2106.09685] LoRA: Low-Rank Adaptation of Large Language Models - arXiv.org', 'url': 'https://arxiv.org/abs/2106.09685', 'content': 'cs arXiv:2106.09685 LoRA: Low-Rank Adaptation of Large Language Models Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. Subjects:   Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) Cite as:    arXiv:2106.09685 [cs.CL] (or arXiv:2106.09685v2 [cs.CL] for this version) cs Bibliographic and Citation Tools Connected Papers Toggle', 'score': 0.84948516, 'raw_content': None}, {'title': 'LoRA: Low-Rank Adaptation from Scratch ‚Äî Code and Theory', 'url': 'https://medium.com/@alexmriggio/lora-low-rank-adaptation-from-scratch-code-and-theory-f31509106650', 'content': 'And that is the aim of LoRA ‚Äî to take the change-in-weight matrix and approximate it with the product of two lower-rank matrices. ... Machine Learning. Lora----1. Follow. Written by AR.', 'score': 0.80771893, 'raw_content': None}, {'title': 'Fine-Tuning Deep Learning Models with Low-Rank Adaptation (LORA): using ...', 'url': 'https://medium.com/@sandha.iitr/fine-tuning-deep-learning-models-with-low-rank-adaptation-lora-using-google-colab-dac1b4516f71', 'content': 'Through LORA_Playground, we aim to provide a practical and insightful resource for the machine learning community, empowering researchers and practitioners to leverage the full potential of LORA', 'score': 0.7823471, 'raw_content': None}], 'response_time': 2.01}), ToolMessage(content='[{\"url\": \"https://timdettmers.com/about/\", \"content\": \"Tim Dettmers is a research scientist at Ai2 and an incoming assistant professor at CMU. He works on efficient deep learning methods, such as quantization, sparsity, and low-bit inference.\"}, {\"url\": \"https://timdettmers.com/\", \"content\": \"Tim Dettmers is a researcher and teacher in deep learning and natural language processing. His blog covers topics such as hardware, quantization, sparse networks, creativity, and grad school choices.\"}, {\"url\": \"https://github.com/TimDettmers\", \"content\": \"Tim Dettmers is a researcher and developer at the University of Washington. He has 53 repositories on GitHub, mostly related to deep learning, sparse learning, and knowledge graphs.\"}, {\"url\": \"https://ai2050.schmidtsciences.org/fellow/tim-dettmers/\", \"content\": \"Tim Dettmers is an Assistant Professor at Carnegie Mellon University and a Research Scientist at the Allen Institute for AI, and his research focuses on making foundation models, such as ChatGPT, accessible to researchers and practitioners by reducing their resource requirements. AI models like ChatGPT work well for general use but fail in specialized expert domains, such as the medical sciences. To make AI models work in expert domains, one must adapt them, which is costly and requires significant AI expertise. This project overcomes these cost and expertise barriers through two new approaches: (1) use AI models themselves to perform the AI model adaptation process automatically; (2) make the adaptation process cheap so it can be run on regular consumer hardware.\"}, {\"url\": \"https://arxiv.org/abs/2208.07339\", \"content\": \"Tim Dettmers is one of the authors of a paper titled LLM.int8, which proposes a method for 8-bit matrix multiplication for transformers at scale. The paper was published at NeurIPS 2022 and shows how to reduce GPU memory for inference in large language models.\"}]', name='tavily_search_results_json', id='38e55736-21fd-459c-858c-e0640e39fc17', tool_call_id='call_YpZhFwpieKG7MeduXwOXbcZY', artifact={'query': 'Tim Dettmers', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'About Me ‚Äî Tim Dettmers', 'url': 'https://timdettmers.com/about/', 'content': 'Tim Dettmers is a research scientist at Ai2 and an incoming assistant professor at CMU. He works on efficient deep learning methods, such as quantization, sparsity, and low-bit inference.', 'score': 0.9407083, 'raw_content': None}, {'title': 'Tim Dettmers ‚Äî Making deep learning accessible.', 'url': 'https://timdettmers.com/', 'content': 'Tim Dettmers is a researcher and teacher in deep learning and natural language processing. His blog covers topics such as hardware, quantization, sparse networks, creativity, and grad school choices.', 'score': 0.9405774, 'raw_content': None}, {'title': 'TimDettmers (Tim Dettmers) ¬∑ GitHub', 'url': 'https://github.com/TimDettmers', 'content': 'Tim Dettmers is a researcher and developer at the University of Washington. He has 53 repositories on GitHub, mostly related to deep learning, sparse learning, and knowledge graphs.', 'score': 0.93735445, 'raw_content': None}, {'title': 'Tim Dettmers - AI2050', 'url': 'https://ai2050.schmidtsciences.org/fellow/tim-dettmers/', 'content': 'Tim Dettmers is an Assistant Professor at Carnegie Mellon University and a Research Scientist at the Allen Institute for AI, and his research focuses on making foundation models, such as ChatGPT, accessible to researchers and practitioners by reducing their resource requirements. AI models like ChatGPT work well for general use but fail in specialized expert domains, such as the medical sciences. To make AI models work in expert domains, one must adapt them, which is costly and requires significant AI expertise. This project overcomes these cost and expertise barriers through two new approaches: (1) use AI models themselves to perform the AI model adaptation process automatically; (2) make the adaptation process cheap so it can be run on regular consumer hardware.', 'score': 0.9263638, 'raw_content': None}, {'title': 'LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale', 'url': 'https://arxiv.org/abs/2208.07339', 'content': 'Tim Dettmers is one of the authors of a paper titled LLM.int8, which proposes a method for 8-bit matrix multiplication for transformers at scale. The paper was published at NeurIPS 2022 and shows how to reduce GPU memory for inference in large language models.', 'score': 0.8638634, 'raw_content': None}], 'response_time': 1.66}), ToolMessage(content='[{\"url\": \"https://pmc.ncbi.nlm.nih.gov/articles/PMC7996841/\", \"content\": \"Generally formulated, attention in machine learning is a sequential process in which a learning task is guided by a set of elements of the input source (or memory). This is achieved by integrating the attention value into the task. Attention mechanisms have provided and will provide a paradigm shift in machine learning.\"}, {\"url\": \"https://www.clrn.org/what-is-attention-in-machine-learning/\", \"content\": \"There are three main types of attention in machine learning: Self-Attention: Self-attention is used within a sequence, such as a sentence or a piece of text, to understand the relationships between different elements.This type of attention is particularly useful for tasks such as language translation, where the model needs to understand the relationships between different words in a sentence.\"}, {\"url\": \"https://www.freecodecamp.org/news/what-are-attention-mechanisms-in-deep-learning/\", \"content\": \"Attention mechanism is a fundamental invention in artificial intelligence and machine learning, redefining the capabilities of deep learning models. This mechanism, inspired by the human mental process of selective focus, has emerged as a pillar in a variety of applications, accelerating developments in natural language processing, computer\"}, {\"url\": \"https://machinelearningmastery.com/what-is-attention/\", \"content\": \"Learn the concept of attention in machine learning and how it relates to biological attention. Explore the components and applications of attention-based systems, such as in machine translation.\"}, {\"url\": \"https://machinelearningmastery.com/the-attention-mechanism-from-scratch/\", \"content\": \"Learn how the attention mechanism improves the performance of sequence-to-sequence models by flexibly focusing on the most relevant parts of the input. See the implementation of the general attention mechanism in Python with NumPy and SciPy.\"}]', name='tavily_search_results_json', id='76d6453e-e9d5-435d-b045-7891d70866ca', tool_call_id='call_4RLFT3RVwqOjGij6gXccysq1', artifact={'query': 'Attention in machine learning', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Attention Mechanisms and Their Applications to Complex Systems', 'url': 'https://pmc.ncbi.nlm.nih.gov/articles/PMC7996841/', 'content': 'Generally formulated, attention in machine learning is a sequential process in which a learning task is guided by a set of elements of the input source (or memory). This is achieved by integrating the attention value into the task. Attention mechanisms have provided and will provide a paradigm shift in machine learning.', 'score': 0.94808257, 'raw_content': None}, {'title': 'What is attention in machine learning? - California Learning Resource ...', 'url': 'https://www.clrn.org/what-is-attention-in-machine-learning/', 'content': 'There are three main types of attention in machine learning: Self-Attention: Self-attention is used within a sequence, such as a sentence or a piece of text, to understand the relationships between different elements.This type of attention is particularly useful for tasks such as language translation, where the model needs to understand the relationships between different words in a sentence.', 'score': 0.8941352, 'raw_content': None}, {'title': 'What are Attention Mechanisms in Deep Learning? - freeCodeCamp.org', 'url': 'https://www.freecodecamp.org/news/what-are-attention-mechanisms-in-deep-learning/', 'content': 'Attention mechanism is a fundamental invention in artificial intelligence and machine learning, redefining the capabilities of deep learning models. This mechanism, inspired by the human mental process of selective focus, has emerged as a pillar in a variety of applications, accelerating developments in natural language processing, computer', 'score': 0.8674071, 'raw_content': None}, {'title': 'What Is Attention? - MachineLearningMastery.com', 'url': 'https://machinelearningmastery.com/what-is-attention/', 'content': 'Learn the concept of attention in machine learning and how it relates to biological attention. Explore the components and applications of attention-based systems, such as in machine translation.', 'score': 0.8245895, 'raw_content': None}, {'title': 'The Attention Mechanism from Scratch - Machine Learning Mastery', 'url': 'https://machinelearningmastery.com/the-attention-mechanism-from-scratch/', 'content': 'Learn how the attention mechanism improves the performance of sequence-to-sequence models by flexibly focusing on the most relevant parts of the input. See the implementation of the general attention mechanism in Python with NumPy and SciPy.', 'score': 0.7185356, 'raw_content': None}], 'response_time': 1.87})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='### LoRA in Machine Learning\\nLoRA, or Low-Rank Adaptation, is a method designed to make large and complex machine learning models more adaptable for specific tasks. It achieves this by adding lightweight, trainable components to the existing model layers, rather than modifying the entire model. This approach significantly reduces the number of trainable parameters and the GPU memory requirements, making it efficient for adapting large language models like GPT-3. LoRA maintains or even improves model performance compared to traditional fine-tuning methods, without increasing inference latency. [Learn more](https://arxiv.org/abs/2106.09685).\\n\\n### Tim Dettmers\\nTim Dettmers is a research scientist at the Allen Institute for AI and an incoming assistant professor at Carnegie Mellon University. His work focuses on efficient deep learning methods, including quantization, sparsity, and low-bit inference. He is known for his contributions to making large AI models more accessible by reducing their resource requirements, enabling their use in specialized domains. [More about Tim Dettmers](https://timdettmers.com/about/).\\n\\n### Attention in Machine Learning\\nAttention mechanisms in machine learning are inspired by the human cognitive process of focusing selectively on certain parts of the input data. They are crucial in tasks like language translation, where understanding the relationships between different elements in a sequence is essential. Attention mechanisms allow models to dynamically focus on the most relevant parts of the input, improving the performance of sequence-to-sequence models. This concept has become a fundamental component in various applications, particularly in natural language processing. [Explore more about attention mechanisms](https://machinelearningmastery.com/what-is-attention/).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 338, 'prompt_tokens': 1672, 'total_tokens': 2010, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'stop', 'logprobs': None}, id='run-a2f620fa-d3f9-46f3-90a1-00def157271b-0', usage_metadata={'input_tokens': 1672, 'output_tokens': 338, 'total_tokens': 2010, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4: LangGraph for the \"Patterns\" of GenAI\n",
        "\n",
        "Let's ask our system about the 4 patterns of Generative AI:\n",
        "\n",
        "1. Prompt Engineering\n",
        "2. RAG\n",
        "3. Fine-tuning\n",
        "4. Agents"
      ],
      "metadata": {
        "id": "yVmZPs6lnpsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patterns = [\"prompt engineering\", \"RAG\", \"fine-tuning\", \"LLM-based agents\"]"
      ],
      "metadata": {
        "id": "ZoLl7GlXoae-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for pattern in patterns:\n",
        "  what_is_string = f\"What is {pattern} and when did it break onto the scene??\"\n",
        "  inputs = {\"messages\" : [HumanMessage(content=what_is_string)]}\n",
        "  messages = agent_with_helpfulness_check.invoke(inputs)\n",
        "  print(messages[\"messages\"][-1].content)\n",
        "  print(\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zkh0YJuCp3Zl",
        "outputId": "d847426e-71b3-47e6-b1ae-351a78d68d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Prompt Engineering: Definition and Importance**\n",
            "\n",
            "Prompt engineering is the process of designing and refining prompts to guide AI models in generating accurate and relevant responses. It involves creating input, instructional, and conversational prompts to minimize bias and improve the quality of AI outputs. This technique is crucial in various applications, including customer support, content generation, and data analysis. Prompt engineering is an iterative process that may require repeated prompting to achieve the desired results, ultimately leading to improved outcomes and cost savings ([Techopedia](https://www.techopedia.com/definition/prompt-engineering), [Britannica](https://www.britannica.com/technology/prompt-engineering)).\n",
            "\n",
            "**History of Prompt Engineering**\n",
            "\n",
            "The history of prompt engineering can be traced back to the early days of code generation tools like CodeSmith and MyGeneration, which automated the generation of boilerplate code for common programming tasks. Over time, prompt engineering evolved with advancements in natural language processing (NLP) and reinforcement learning techniques. These developments have enhanced the capabilities of language models, making them more powerful, context-aware, and adaptable for a wide range of NLP applications. The introduction of attention mechanisms and reinforcement learning in 2017 further improved the controllability of prompt-engineered language models, allowing engineers to shape model behavior and address biases ([Promptly Substack](https://promptly.substack.com/p/a-journey-through-the-history-of), [arXiv](https://arxiv.org/abs/2310.04438)).\n",
            "\n",
            "\n",
            "\n",
            "Retrieval-Augmented Generation (RAG) is a technology that enhances generative models by integrating information retrieval capabilities. It allows large language models (LLMs) to respond to user queries by referencing a specified set of documents, thereby augmenting the information drawn from these sources. This approach is particularly useful for generating more accurate and contextually appropriate responses, informative articles, personalized learning content, and improved recommendation systems.\n",
            "\n",
            "RAG was first proposed in 2020, making it a relatively new technology. Since its inception, it has gained popularity due to its ability to enhance the capabilities of LLMs in knowledge-intensive tasks. The technology has evolved to include advanced retrievers and complementary technologies, leading to more complex RAG systems. Recent research has focused on modular RAG frameworks, which decompose complex systems into independent modules, allowing for a more reconfigurable and efficient design.\n",
            "\n",
            "For more detailed insights, you can explore the following resources:\n",
            "- [Medium article on RAG](https://medium.com/@matthasan/all-you-want-to-know-about-rag-e2b4bf832695)\n",
            "- [Makebot.ai overview of RAG](https://www.makebot.ai/blog-en/retrieval-augmented-generation-rag-overview-history-process)\n",
            "- [Wikipedia entry on RAG](https://en.wikipedia.org/wiki/Retrieval-augmented_generation)\n",
            "- [Oracle's explanation of RAG](https://www.oracle.com/artificial-intelligence/generative-ai/retrieval-augmented-generation-rag/)\n",
            "- [Research papers on advanced RAG systems](https://arxiv.org/abs/2407.02695)\n",
            "\n",
            "\n",
            "\n",
            "Fine-tuning is a process in machine learning where a pre-trained model is further trained on a smaller, task-specific dataset. This allows the model to adapt to specific tasks or domains while leveraging the general knowledge it has already acquired during its initial training on a larger dataset. Fine-tuning is particularly useful because it can significantly reduce the amount of data and computational resources required to train a model for a specific task, as the model starts with a strong foundation of general knowledge.\n",
            "\n",
            "Fine-tuning became prominent with the rise of transfer learning techniques, especially in the field of natural language processing (NLP) and computer vision. In NLP, the introduction of models like BERT (Bidirectional Encoder Representations from Transformers) in 2018 popularized the concept of fine-tuning. BERT and similar models are pre-trained on large corpora of text and then fine-tuned on specific tasks such as sentiment analysis, question answering, or named entity recognition.\n",
            "\n",
            "In computer vision, fine-tuning has been used for a longer time, with models like AlexNet, VGG, and ResNet being pre-trained on large datasets like ImageNet and then fine-tuned for specific image classification tasks.\n",
            "\n",
            "Overall, fine-tuning has become a standard practice in machine learning, enabling more efficient and effective model training across various domains.\n",
            "\n",
            "\n",
            "\n",
            "LLM-based agents, or Large Language Model-based agents, are AI systems that utilize large language models to perform tasks, interact, and exhibit behaviors akin to human agents. These agents are designed to perceive their environment, process information, and make decisions or take actions based on their programming and learned data.\n",
            "\n",
            "The emergence of LLM-based agents has been a significant development in the field of artificial intelligence. The field has seen explosive growth in recent years, with researchers exploring various approaches to agent architectures and interaction paradigms. A key breakthrough in their development was the introduction of the ReAct paradigm, which combines reasoning and acting, providing a simple and unifying solution for LLM agents.\n",
            "\n",
            "For more detailed information, you can refer to the following resources:\n",
            "\n",
            "1. [History in the Making: LLM (AI) Agents and How We Got Here](https://ai.gopubby.com/history-in-the-making-llm-ai-agents-and-how-we-got-here-361138829641)\n",
            "2. [A Brief History of LLM Agents](https://medium.com/@wgsjack199213_24772/llm-agents-a-brief-history-and-overview-f73468251179)\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}